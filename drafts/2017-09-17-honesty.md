---
layout: post
title:  "In favor of truth-seeking youthful activism"
date:   "2017-09-13"
tags: effective-altruism
---

[Epistemic status: I am confident that the policy I'm proposing would have been better for me. Other people are probably better at maintaining internal beliefs in the face of emphasising other things externally, and so this advice isn't as good for them.]

Similar posts: ["Rationality: Common Interest of Many Causes"](http://lesswrong.com/lw/66/rationality_common_interest_of_many_causes/)

When I was younger, I often talked to people with the intention to persuade them rather than to inform them and learn from them. This was particularly true of a few topics that I thought were really morally important, such as animal suffering, x-risk, and immigration restrictions. I had a tendency to be overconfident, to exaggerate things, to draw attention away from the weaknesses in my arguments, and to understate my uncertainty.

I think that this was overall a big mistake. I missed a lot of opportunities to improve my understanding of important subjects. I was probably less persuasive and probably sounded stupid pretty often. I was a worse member of the EA community. And I put myself in a mindset in which I wasn't as able to critically evaluate new evidence as it appeared.

I think that many other EAs make similar mistakes; I generally wish that they'd focus less on persuading others and more on improving their understanding of subjects that they talk about.

In the rest of this post I'll give more detail about all those considerations, and at the end I'll suggest some strategies that I think might mitigate many of the downsides of optimizing for persuasion.

### Missed opportunities for learning

Even when you're talking to people who don't understand a subject very well and don't have good ideas to contribute, they often ask questions which it's worth your time to think about. For example, when you talk to people about animal rights, they often bring up questions about the empirical welfare of various animals, or about farm animal welfare regulations, or about various technologies for animal product alternatives.

If my goal when talking to people about animal rights in college had been to give people really solid and accurate information about all these questions, I think I would have been roughly as persuasive, but I also would have ended up far more knowledgeable and better at researching these topics. If I had then decided to focus on animal welfare with my career, I think that this knowledge and research practice would have been very useful, much more so in expectation than having a little bit more practice persuading individuals. And this knowledge would also have been helpful in my [cause prioritization](https://80000hours.org/2014/01/which-cause-is-most-effective-300/), both within cause areas and between them.

Here's another example: I often argue with people about economic policies like the minimum wage, labor regulations, zoning restrictions, rent control, and immigration. I am more libertarian than most of the Silicon Valley liberals I argue with. Though I am normally not convinced by them, they often make empirical arguments which are healthy for me to consider more carefully, for example bringing up things like the destruction of communities caused by displacing people through higher rent or reasons to prefer labor regulation to employee-employer regulation (see section 2.5 [here](http://slatestarcodex.com/2017/02/22/repost-the-non-libertarian-faq/#coordination_problems), which I think goes too far but points in the right direction). I think that I am overall better informed as a result of being prompted to think about concerns which normally don't feel as salient to me.

At this point in my life, I feel like it's very valuable for me to have more accurate opinions, because I think that I can have unusually high impact with my career, which requires me to make good decisions about what to work on. I think that this is probably significantly more valuable than the at most couple of dozen people who are more favorably disposed to animal rights as a result of talking to me. (Except if you include the people who are EA as a result of my influence, and TODO.)

(I can imagine ways that the world could be different such that this point seemed less true. For example, if all of the questions that people had about animal rights were really focused on the welfare of animals in shelters, or dumb concerns about [the effect of quinoa consumption on Bolivian farmers](http://www.npr.org/sections/thesalt/2016/03/31/472453674/your-quinoa-habit-really-did-help-perus-poor-but-theres-trouble-ahead), then directing your attention based on the questions of the people you talk to would seem like a worse idea.)

(Another argument against: If I were being maximally honest, maybe I would have mentioned in every conversation about animal welfare, "Oh by the way, I think that because of the environmental destruction caused by animal farming, it [might be overall good to eat beef](http://reducing-suffering.org/vegetarianism-and-wild-animals/)". I think this might have been distracting and overall unhelpful.)

In most of my life so far, the potential benefits of persuading people were not large enough to outweigh the benefits I would have gained by trying to be maximally honest and informed, especially given that I'm not sure that this strategy would have been less persuasive.

### Lack of improved persuasiveness

I think that the high-honesty strategy I'm describing would have been much more persuasive after I'd followed it for a year, because I would have become much more informed and I feel like knowing a subject better is actually pretty useful for being persuasive when talking about it.

(This is especially true when talking about potentially heated political issues. If someone says "Immigrants are destroying American culture", it's often really handy to steer the conversation into empirical questions of how we would measure that claim and what kinds of evidence we think is available.)

The strategy I'm suggesting also fails much more gracefully when you're talking to someone who's more informed than you, or when you're wrong. I think that I normally wasn't wrong about the general point of things I was arguing, but I was often wrong about minor empirical points, and my overconfidence in those made me sound very foolish.

To some extent, I was engaging in a worst-of-both-worlds approach, where I wasn't adopting the persuasion-optimized debate technique of steering the conversation into the areas where I knew the facts the best, but where I also didn't know the subjects broadly enough to pull off confident assertions in all the areas that came up.

Overconfidence is an especially foolish when presenting crazy-sounding, unpopular, or half-baked ideas. I used to do a particularly bad job when arguing for concern over wild animal suffering. I insufficiently communicated my uncertainty about what interventions would be good. I wish that I'd just tried to present the idea as something that seemed important, and discussed the kinds of questions that I thought should be investigated further.

### Costs imposed on my allies

Even if I was correct that it was worth being overconfident in conversations with the general public, I should definitely not have behaved this way in internal EA discussion. I think I did, and I regret this. I think that the fact that I behaved badly in this way is one of the strongest arguments for being truth-seeking in all my conversations.

For example, I think I acted more confident than I should have been  EXAMPLES OF DOING THIS INTERNALLY.

It's defecting (because you're making EA less of what you want it to be) and it's unilateralist curse-ish.

This kind of approach also has positive externalities, because if you try to persuade people just by telling them the best summary of relevant information that you know, even if you're wrong you're doing them a service.

I feel like there are a lot of people in EA who seem to be in it just for picking people off to their own causes.

There are also a lot of people in EA who are privately a lot less confident-sounding in their beliefs. They say things like "Well, my personal facebook page isn't for EAs, it's for my more general circles". This is maybe reasonable but ends up being pretty costly.

### Encouraging rationalization

If you allow yourself to have subjects where you think it's more important to be persuasive than to notice when you're wrong, then you've given yourself a free pass for being wrong on those topics. As a human it's really hard and unnatural to focus on the ways that you arguments are weak, so making it even easier for yourself is really dangerous.

They say that you should [keep two books, not no books](http://lesswrong.com/lw/dg/theism_wednesday_and_not_being_adopted/8dgj?context=1#comments). I think that once I thought it was okay to say things that were persuasive but not maximally accurate, I slipped right into thinking it was okay to be sloppy about what I actually believed.

### My advice to people who want to practice activism

- Maybe have two blogs; one for persuasion and one for describing your learning and beliefs
- Have internal discussions where you try to cultivate the best subtle arguments that suggest weird things about your positions
- Spend some time in a different space, trying to evaluate that one critically. Eg if you're an open borders advocate, maybe also spend some time thinking about criminal justice reform.
- Have an internal culture which prizes making good and unusual arguments against the stuff the ingroup advocates. I don't know how to make this healthy culture of contrarianism happen.
- Maybe: Make an explicit list of the differences between what you emphasize in your public discussions and how you think about the subject yourself. TODO: explain how this isn't just advocating for dishonesty.

----

Why are there so many reasons that this is a bad idea? We should generally be suspicious when there are lots of independent seeming considerations which are all pointing the same way.


I still make this mistake, but less and less often. TODO: what caused this change

related mistakes that I make:

- trying to be funny/insightful
- getting frustrated and trying to baldly assert that people are wrong


https://openborders.info is the epitome of doing what I'm talking about.
