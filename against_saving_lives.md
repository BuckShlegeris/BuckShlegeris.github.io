# Against saving lives and avoiding death

I think that many of my rationalist/EF friends care too much about saving lives and avoiding death. I think they should try to reduce suffering and create happiness instead.

I've been thinking about this for the last few weeks, and I've only just noticed now the pervasiveness of saving a life as the standard unit of measurement in ethics. It's how we phrase moral dilemmas, and how we describe good human charities. I think that it's dangerous to have this idea that morality is about saving lives or QALYs, analogously to how it's a problem to fetishize GDP in economics.

## My moral preferences

My moral preferences are fairly well described as total utilitarian. I don't preference real people or events over hypothetical or future people or events. To me, the good thing about a life is that it enables the person living it to feel happiness and satisfaction and all those emotions which I value.

From this perspective, dying at thirty isn't as bad as never being born at all. The only problem with dying at thirty is the suffering it causes to you and others, and the loss of the opportunity to have the rest of your happy life.

It's really easy to create more human lives, and in the future it will be even easier. I don't think we should focus on saving the lives of humans now when we can easily just make more later. Particularly when the effort we put into saving lives now comes at the cost of reducing suffering now or improving the future.

In the far future, if all goes well, the population of the universe will be limited by the energy available. In that case, keeping someone alive will be at the cost of creating a new life. It's not entirely obvious to me that we'll choose to keep people alive instead of letting them die and creating new ones.

## Why would we have this intuition?

I think that our interest in saving lives, as opposed to creating happy lives, partially comes from confusing a good game theory heuristic for a moral rule. Just like we're all better off with a rule against theft, even though theft sometimes has a utilitarian justification, the people who currently exist and thus make the rules are better off with a rule against murder. It's also a lot harder to see a life lost when you choose not to have a child compared to when someone dies: when you know someone, you're already used to thinking about what they'll be doing in ten years time, and suddenly you have to revise that. You don't get such a shock when you choose to not create a hypothetical person, because you don't know anything about what they'll do.

##  How should this make us think about what charity to give to?

For one, I don't care about saving the lives of factory farmed animals: I'm happy with them being killed as soon as possible. Some animal welfare advocates disagree with me on this one.

What about human charities? In the short term, if I wanted to increase human happiness, I'd be less likely to give to life-saving initiatives and more likely to give to GiveDirectly.

However, the long term is what matters. The future has the potential for far more sentient life than currently exists. For this reason, I'm not very interested in saving human lives unless that's strongly linked to making far future stuff work better. Some people reckon that reducing poverty is good for increasing global co-operation and so on. That could convince me.


## Cryonics?

What about personally? I claim to not arbitrarily prefer my life to anyone else's. However, I certainly *selfishly* want to live forever, as I might if the singularity turns out well. Obviously, money spent on charity is money spent better than on my own cryonics. However, I'm not living for literally as little money as possible. I could buy cryonics out of my personal spending budget and just consider it a luxury like my guitar. Next time I'm going to be living in America for a while, maybe I should sign up.