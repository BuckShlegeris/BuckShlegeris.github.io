<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Buck Shlegeris</title>
  <meta name="description" content="Website of Buck Shlegeris.
">


  <link rel="stylesheet" href="/bootstrap.css">
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://bshlgrs.github.io/">
  <link rel="alternate" type="application/rss+xml" title="Buck Shlegeris" href="http://bshlgrs.github.io/feed.xml">
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$latex', '$'] ],
        displayMath: [ ['$$', '$$']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      messageStyle: "none",
      "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
    });
  </script>
  <script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
  <script src="/jquery.js"></script>
  <script type="text/babel" src="/main.js"></script>
  
</head>


  <body>

    

    <div class="container">
  <div class="row">
    <div class="col-sm-7 col-sm-offset-1 markdownify">
      
      <p class="post-meta"><time datetime="1969-12-31T16:00:00-08:00" itemprop="datePublished"></time></p>

      <hr/>

      <h1>Buck Shlegeris</h1>

<div class="lead">
I am a software engineer from Australia. I have lived in San Francisco for most of the last three years. I'm interested in data structures and effective altruism. Here are some things that I've written recently:
</div>


  <h2><a href="/2016/06/22/ctci.html"> Studying for startup interviews with 'Cracking the Coding Interview'</a></h2>

  <p class="post-meta"><time datetime="2016-06-22T00:00:00-07:00" itemprop="datePublished">Jun 22, 2016</time></p>

  <div class="shrink-headings">
    <p><a href="https://www.amazon.com/Cracking-Coding-Interview-Programming-Questions/dp/098478280X">Cracking the Coding Interview</a> is by far the most popular interview prep book for software engineers. But it was written for a few years ago, and software engineering interviews seem to have changed in the meantime, at least in the Silicon Valley engineering culture which I’m most involved in.</p>

<p>So I’ve written this guide to the book. It contains notes on things which I think have changed since it was written, and a list of the questions from the book which I think are most relevant to people preparing for software engineering interviews at good companies in the Bay Area.</p>

<p>I was inspired to write this by <a href="https://www.interviewcake.com/">InterviewCake</a>, which is a competitor to Cracking the Coding Interview. But InterviewCake is much more expensive than CtCI. My goal is to create a resource which lets you use Cracking the Coding Interview more effectively, so that you can save the extra $150 difference.</p>

<h2 id="general-notes">General notes</h2>

<p>Every chapter in the interview questions section of CtCI starts with a short summary of the subject matter for the questions. I think these notes are quite good. It’s well worth reading the notes for chapters even if you don’t do questions from them.</p>

<p>The first 40-ish pages of the book are general advice about software engineering interviews. I agree with all of it except the following points, organized by section:</p>

<p><strong>Before the interview</strong>: Companies don’t ask behavioral questions much.</p>

<p><strong>What You Need To Know (page 26)</strong>: Tries are not absolutely must-have knowledge. I’ve never heard of people being asked to implement quicksort in place. Singleton and Factory design patterns are not crucial knowledge.</p>

<p><strong>At the Interview</strong>: You don’t have to use C, C++, or Java. People will possibly be biased against you if you do. Ruby, Python, and Javascript are fine choices. I think it’s fine to do the problem in whatever language you want. You can ask your recruiter about this before the interview.</p>

<h2 id="the-most-relevant-questions">The most relevant questions</h2>

<p>Here is a subset of the questions which I think reflects SF software interviews more accurately:</p>

<p>1.1, 1.7, 1.8, 2.1, 3.1, 3.2, 3.3, 3.5, 4.1, 4.2, 4.3, 4.5, 4.8, 7.1, 7.2, 7.4, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 9.2, 9.3, 9.6, 12.1, 12.2, 12.6, 12.7, 15.3, 17.5, 18.1, 18.2, 19.2, 19.7, 19.11, 20.10, 20.11.</p>

<p>I would recommend giving these questions higher priority in your study.</p>

<h2 id="comments-on-individual-question-chapters">Comments on individual question chapters:</h2>

<h3 id="chapter-1-arrays-and-strings">Chapter 1: Arrays and Strings</h3>

<p>Companies care less about seeing you edit data in place than they used to. I’d only expect questions on this if you’re applying for a C job. For this reason, questions [1.2, 1.3, 1.5, 1.6, 1.7] are lower priority.</p>

<h3 id="chapter-2-linked-lists">Chapter 2: Linked Lists</h3>

<p>All of these questions are less common these days because linked lists come up less because we don’t use C as much.</p>

<p><a href="http://bshlgrs.github.io/2016/04/22/dumbest-algorithm-problem.html">Fuck question 2.2.</a></p>

<p>2.5 is a common bullshit brainteaser question.</p>

<h3 id="chapter-3-queues-and-stacks">Chapter 3: Queues and stacks</h3>

<p>I agree that you’ll look good if you can flawlessly implement a queue and stack.</p>

<h3 id="chapter-4-graphs-and-trees">Chapter 4: Graphs and trees</h3>

<p>Study BFS, it’s a really common question.</p>

<h3 id="chapter-5-bit-manipulation">Chapter 5: Bit manipulation</h3>

<p>I’ve rarely seen these problems come up, even when I interviewed for a C++ systems job.</p>

<h3 id="chapter-6-brainteasers">Chapter 6: Brainteasers</h3>

<p>These questions are widely reviled, and seem to be getting less common. Maybe memorize the answers in case you run across a bad interviewer.</p>

<h3 id="chapter-7-oop">Chapter 7: OOP</h3>

<p>These questions are good. The provided answers are idiomatic Java; if you’re answering in Python you should model your answers after idiomatic Python rather than the answers given.</p>

<p>I don’t hear about people being asked abstract questions like 7.3.</p>

<h3 id="chapter-8-recursion">Chapter 8: Recursion</h3>

<p>Many of these questions are classics which I’ve been asked many times before.</p>

<h3 id="chapter-9-searching-and-sorting">Chapter 9: Searching and sorting</h3>

<p>I think that it’s somewhat less common to be asked to write sorting algorithms these days.</p>

<h3 id="chapter-10-math">Chapter 10: Math</h3>

<p>I don’t hear about math questions being asked, except at extremely math heavy companies to applicants with a hardcore math background.</p>

<h3 id="chapter-11-testing">Chapter 11: testing</h3>

<p>I don’t hear about these questions very much. I’ve never heard questions like “how would you test a pen”.</p>

<h3 id="chapter-12-system-design-and-memory-limits">Chapter 12: system design and memory limits</h3>

<p>I don’t hear about memory limit questions very often.</p>

<h3 id="chapter-13-and-14-c-and-java">Chapter 13 and 14: C++ and Java</h3>

<p>Only relevant if you’re interviewing in C++ or Java, and even then I’d be slightly surprised to get these questions.</p>

<h3 id="chapter-15-databases">Chapter 15: Databases</h3>

<p>The advice given is somewhat out of date. I don’t think that I’ve ever heard about someone being asked to denormalize their SQL database schema for speed.</p>

<p>I think the “design a database to hold certain data” type questions are more common now. The rise of ORMs has led to SQL being somewhat less important for most developers.</p>

<h3 id="chapter-16-low-level">Chapter 16: Low level</h3>

<p>These questions are great, but I wouldn’t expect them at most generalist job interviews.</p>

<h3 id="chapter-17-networking">Chapter 17: Networking</h3>

<p>This is somewhat more low level than I think most people get asked. It’s worth knowing the answer to the famous “what happens after you type a URL into a browser” question though.</p>

<h3 id="chapter-18-threads-and-locks">Chapter 18: Threads and Locks</h3>

<p>Companies don’t seem to ask about concurrency primitives without warning you beforehand. Some of these questions are Java-specific.</p>

<h3 id="chapter-19-and-20-moderate-and-hard">Chapter 19 and 20: Moderate and Hard</h3>

<p>All these questions are popular questions. I don’t particularly like them.</p>

  </div>

  <hr />

  <h2><a href="/2016/06/16/kth-richest.html"> 'Who is the kth richest person with age between x and y'</a></h2>

  <p class="post-meta"><time datetime="2016-06-16T00:00:00-07:00" itemprop="datePublished">Jun 16, 2016</time></p>

  <div class="shrink-headings">
    <p>Suppose I want to maintain a set of people where each has an age and a wealth. I want to be able to quickly insert people, delete people, and answer queries of the form “find the $latex k$th richest person whose age is between $latex x$ and $latex y$”.</p>

<p>Here is a summary of solutions to different variants on this question:</p>

<table class="table" id="table1">
  <tr>
    <th>Variation</th>
    <th>Solution details</th>
    <th>Space</th>
    <th>Update time</th>
    <th>Query time</th>
  </tr>
  <tr>
    <td>No insertion or deletion, one-sided interval</td>
    <td><a href="http://stackoverflow.com/a/31162190/1360429">Persistent binary search trees</a></td>
    <td>$latex n \cdot \log(n)$</td>
    <td>N/A</td>
    <td>$latex \log(n)$</td>
  </tr>
  <tr>
    <td>No insertion or deletion, two-sided interval</td>
    <td><a href="http://stackoverflow.com/questions/26296624/order-statistic-on-intervals/26299986#26299986">Persistent binary search trees</a></td>
    <td>$latex n \cdot \log(n)$</td>
    <td>N/A</td>
    <td>$latex \log(n)$</td>
  </tr>
  <tr>
    <td>Insertion, deletion, two-sided interval</td>
    <td>My answer, presented here</td>
    <td>$latex n \cdot \log(n)$</td>
    <td>$latex \log^2(n)$</td>
    <td>$latex \log^3(n)$</td>
  </tr>
</table>

<p>I have been somewhat interested in this question for about a year, and I’ve asked about related questions <a href="https://www.facebook.com/bshlgrs/posts/10205556609689335">a few</a> <a href="http://stackoverflow.com/questions/31153033/data-structure-to-support-a-particular-query-on-a-set-of-2d-points">times</a>. But no-one’s ever managed to give me a complete answer.</p>

<p>The other day, I ran across <a href="http://stackoverflow.com/a/26299986/1360429">this StackOverflow answer</a>, which presents an answer which I modified to make a full solution, which I’ll present here.</p>

<p>My solution allows insertion and deletion in $latex O(\log^2(n))$, and allows the query in $latex O(\log^3(n))$.</p>

<h2 id="solution">Solution</h2>

<p>Store an <a href="https://en.wikipedia.org/wiki/Order_statistic_tree">order statistic tree</a> ordered on age. At every node, store a pointer to an auxiliary order statistic tree, of all of that node’s descendants ordered on income.</p>

<p>At every node, this requires an extra amount of memory which is linear in the number of descendants of that node. So this means that the tree will take $latex O(n\cdot \log(n))$ memory overall.</p>

<h3 id="query">Query</h3>

<p>You might want to go read <a href="http://stackoverflow.com/a/26299986/1360429">that second StackOverflow answer</a> again, because this algorithm is similar to that one, and it’s easier to understand the algorithm on arrays.</p>

<p>The query is similar to how queries across ranges of an augmented BST usually work: we start out by finding the set of nodes whose descendants contain the whole subsection of the tree that you care about. There will be $latex \log(n)$ of these nodes, and finding all of them takes $latex \log(n)$ time.</p>

<p>We end up with $latex \log(n)$ OSTs of maximum size $latex O(n)$, and we want to find the $latex k$th smallest item in their disjoint union.</p>

<p>As discussed <a href="/2016/06/16/generalized-multi-quickselect.html">here</a>, we can solve that query in $latex O\left(\log(n)^3\right)$.</p>

<p>Alternatively, if your $latex k$ is small, you can directly traverse the trees to find the correct answer, which takes $latex k \log(n) + n$ time.</p>

<h3 id="updates">Updates</h3>

<p>When I insert a new value into my set, I need to update the auxiliary OSTs of all of the ancestor nodes of my new node.</p>

<p>Usually, it’s easy to argue that maintaining auxiliary data in your OST is fast, because usually your auxiliary data is something like “the sum of your descendants” or something which is $latex O(1)$. In this data structure, the efficiency argument is somewhat more complicated.</p>

<p>Inserting a single item into an OST takes $latex O(\log(n))$ time. But making the OST from scratch takes $latex O(n)$. This is concerning because it means that tree rotations are potentially extremely expensive. If I had to do tree rotations all the way up from my new node to the root of the tree every single insertion, then insertion would take linear time.</p>

<p>Luckily, we can decide that our OST is balanced using the red-black tree rules. Insertion in a red-black tree only involves amortized $latex O(1)$ rotations. (See <a href="web.stanford.edu/class/cs166/lectures/05/Small05.pdf">here</a> for an explanation of this.)</p>

<p>The node at the lowest level will have to totally regenerate its auxiliary OST every insertion, of course. Its parent will have to do a tree rotation which requires it to totally regenerate its auxiliary OST every second insertion. Its grandparent will need to do that $latex \frac14$ of the time. And then $latex \frac18$ and so on.</p>

<p>At height $latex h$ in the tree, defining the leaves to be $latex h=0$, the amortized cost of insertion is going to be $latex O(\log(2^h)) = O(h)$ for insertion plus $latex O\left(\frac{2^h}{2^h}\right) = O(1)$ for totally recreating the OST after a rebalance, for a total cost of $latex O(h)$.</p>

<p>The total time required for updating all the auxiliary OSTs after an insert is therefore:</p>

<script type="math/tex; mode=display">O\left(\sum_{h=0}^{log(n)} h \right)= O\left(\log(n)^2\right)</script>

<p>Updating or deleting a node also takes $latex O\left(\log(n)^2\right)$, for the same reason.</p>

<h2 id="variations">Variations</h2>

<h3 id="limited-latex-k">limited $latex k$</h3>

<p>If $latex k$ is always going to fixed below a particular limit $latex l$–say, you know ahead of time that you’re never going to need to know farther back than the 50th richest person between two ages–each node in your main OST can store a smaller auxiliary tree with only $latex l$ elements in it.</p>

<p>This reduces memory requirements to $latex O(n \cdot l)$.</p>

<p><strong>Queries</strong>: Using the algorithm for OSTs in <a href="/2016/06/16/generalized-multi-quickselect.html#table1">this table</a>, the cost is now $latex \log(\log(n) \cdot l) \cdot \log(n) \cdot \log(l)$, which looks like $latex \log(\log(n)) \cdot \log(n) \cdot \log(l)$ as $latex n$ grows.</p>

<p><strong>Updates</strong>: Every ancestor needs to do $latex \log(l)$ work now, instead of $latex \log(n)$, but you still have $latex \log(n)$ ancestors. So update takes overall $latex \log(n)\log(l)$ time.</p>

  </div>

  <hr />

  <h2><a href="/2016/06/16/generalized-multi-quickselect.html"> Generalized multi-quickselect</a></h2>

  <p class="post-meta"><time datetime="2016-06-16T00:00:00-07:00" itemprop="datePublished">Jun 16, 2016</time></p>

  <div class="shrink-headings">
    <p>I’ve been thinking a lot recently about how you find the $latex k$th smallest element in the disjoint union of several data structures.</p>

<h2 id="multi-quickselect-on-data-structures-with-fast-rank">Multi-quickselect on data structures with fast <code class="highlighter-rouge">rank</code></h2>

<p>Yesterday I <a href="/2016/06/15/multi-sorted-array-quickselect">came up with an algorithm similar to quickselect</a> for the version of this problem where you have multiple sorted arrays.</p>

<p>But this algorithm also works on any other data structure which supports the <code class="highlighter-rouge">rank</code> method in $latex O(\log(n))$ time.</p>

<p>On a collection of data structures with a total of $latex O(t)$ elements, the modified quickselect algorithm involves $latex O(log(t))$ iterations. In each iteration, the rank of a random element is computed in every data structure.</p>

<p>So the total time taken is (time to calculate rank in every data structure) * (log of total number of elements).</p>

<table class="table" id="table1">
  <tr>
    <th>Collection</th>
    <th>Time complexity</th>
  </tr>
  <tr>
    <td>$latex m$ sorted arrays of average length $latex n$</td>
    <td>$latex \log(m \cdot n) \cdot m \cdot \log(n)$</td>
  </tr>
    <tr>
    <td>$latex m$ sorted arrays of total length $latex t$</td>
    <td>$latex \log(t) \cdot m \cdot \log(\frac tm)$</td>
  </tr>
  <tr>
    <td>Two sorted arrays, of lengths $latex a$ and $latex b$</td>
    <td>$latex \log(a + b)^2$</td>
  </tr>
  <tr>
    <td>$latex m$ order statistic trees of average size $latex n$</td>
    <td>$latex \log(m \cdot n) \cdot m \cdot \log(n)$</td>
  </tr>
  <tr>
    <td>$latex \log(n)$ sorted arrays of sizes $latex [1, 2, 4, ...n]$</td>
    <td>$latex \log(n)^3$ </td>
  </tr>
</table>

<p>(See <sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup> for more details on the exponentially shrinking arrays.)</p>

<p>For data structures with $latex O(log(n))$ <code class="highlighter-rouge">rank</code>, I think this is optimal.</p>

<h2 id="allowing-data-structures-without-fast-rank">Allowing data structures without fast <code class="highlighter-rouge">rank</code></h2>

<p>How about if some of your data structures are unsorted?</p>

<p>This algorithm needs to be modified, because there’s no particular guarantee that any data structure gets smaller on a particular iteration. This is okay in cases where <code class="highlighter-rouge">rank</code> is cheap enough that the asymptotic complexity isn’t affected by having a data structure which stays at its original size for most of the runtime of the algorithm. But on an unsorted array, <code class="highlighter-rouge">rank</code> takes $latex O(n)$ and a key part of the argument for the good runtime of quickselect is that the unordered array usually gets smaller every time you call <code class="highlighter-rouge">rank</code>.</p>

<p>This issue is why my attempt at an <a href="/2016/06/12/quickselect-lemma.html">optimal algorithm for selection on an OST and an unsorted array</a> was so complex.</p>

<p>Obviously there’s not going to be a sublinear time solution to this problem. So we might as well take linear time to add all our unsorted structures together into an unsorted array, in linear time. So we only need to consider the problem where we have a single unsorted array.</p>

<h3 id="non-optimal-solution">Non-optimal solution</h3>

<p>When I have a collection of data structures such that <code class="highlighter-rouge">rank</code> takes time $latex O(r)$ and <code class="highlighter-rouge">select</code> takes time $latex O(s)$, I can run <a href="/2016/06/12/quickselect-lemma.html">my <code class="highlighter-rouge">double_quickselect_v2</code> algorithm</a> on an unordered array of length $latex n$ and that collection, with query time $latex O(\log(n) \cdot r + s)$. For example, this algorithm can deal with a sorted array of size $latex m$ and an unsorted array of size $latex n$ in overall $latex O(\log(n) \cdot \log(m) + \log(m)) = O(\log(m)\cdot\log(n))$.</p>

<h3 id="what-an-optimal-solution-might-look-like">What an optimal solution might look like</h3>

<p>I bet we can generalize my alleged <a href="/2016/06/12/quickselect-lemma.html">optimal algorithm for selection on an OST and an unsorted array</a>.</p>

<h2 id="summary">Summary</h2>

<p>I have a bunch of data structures and want to find the $latex k$th smallest item in their union. How long will it take me?</p>

<table class="table" id="table1">
  <tr>
    <th>Collection</th>
    <th>Algorithm</th>
    <th>Time complexity</th>
  </tr>
  <tr>
    <td>Unsorted array of size $latex n$</td>
    <td>Median of medians</td>
    <td>Worst case $latex O(n)$</td>
  </tr>
  <tr>
    <td>Sorted array of size $latex n$</td>
    <td>Binary search</td>
    <td>Worst case $latex O(\log(n))$</td>
  </tr>
  <tr>
    <td>Order statistic tree</td>
    <td>its native `find` implementation</td>
    <td>Worst case $latex O(\log(n))$</td>
  </tr>
  <tr>
    <td>A bunch of unsorted data structures, of total size $latex O(n)$</td>
    <td>Stick it all in an array then call median of medians</td>
    <td>Worst case $latex O(\log(n))$</td>
  </tr>
  <tr>
    <td>$latex m$ data structures which support <code>rank</code> in $latex O(\log(n))$, with maximum size $latex O(n)$</td>
    <td><a href="/2016/06/15/multi-sorted-array-quickselect.html">Multi sorted array quickselect</a></td>
    <td>Average case $latex O(m \cdot \log(n) \cdot \log(m \cdot n))$</td>
  </tr>
  <tr>
    <td>$latex m$ data structures which support <code>rank</code> in $latex O(\log(n))$, with maximum size $latex O(n)$, and also a bunch of unsorted data with total size $latex u$</td>
    <td>"Non-optimal solution" as described above</td>
    <td>Average case $latex O(\log(u) \cdot m \cdot \log(n) +\\ m \cdot \log(n) \cdot \log(m \cdot n))$</td>
  </tr>
</table>

<p>I suspect that I can improve upon most of the algorithms listed there that I invented myself; I’ll keep this table updated.</p>

<p>If you know a faster algorithm for one of these problems, please let me know!</p>

<div class="footnotes">
  <ol>
    <li id="fn:1">

      <p>There are a total of $latex 2\cdot n - 1 = O(n)$ elements in those $latex n$ arrays. The inner loop will happen $latex \log(n)$ times.</p>

      <p>Each iteration will need to do a binary search within its array. On the first iteration the time taken will be $latex \sum_{i=0}^{\log(n)} \log(2^i) = O(\log(n)^2)$. Further iterations obviously won’t be slower than that. So we can bound above this runtime by $latex \log(n)$.</p>

      <p>We can also give a proof sketch for bounding it below. Suppose that all our arrays have roughly the same distribution, so that on the $latex w$th iteration, every array has a size of only $latex 2^{-w}$ its original size.</p>

      <script type="math/tex; mode=display">% <![CDATA[
\begin{align} &\sum_{w=0}^{\log(n)} \sum_{i=0}^{\log(n)} \log\left(max\left(2^i \cdot 2^{-w}, 0\right)\right)  \\
        = &\sum_{w=0}^{\log(n)} \sum_{i=0}^{w} i  \\
        = &\sum_{w=0}^{\log(n)} O\left( w^2 \right) \\
        = &O\left(\log(n)^3\right) \end{align} %]]></script>
      <p><a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>

  </div>

  <hr />

  <h2><a href="/2016/06/15/multi-sorted-array-quickselect.html"> Quickselect on multiple sorted arrays</a></h2>

  <p class="post-meta"><time datetime="2016-06-15T00:00:00-07:00" itemprop="datePublished">Jun 15, 2016</time></p>

  <div class="shrink-headings">
    <p><strong>Edit: Thanks heaps to <a href="http://stackoverflow.com/users/1009831/evgeny-kluev">Evgeny Kluev</a>, the author of that original StackOverflow answer, for noticing that I’d made a mistake in the total time complexity calculation.</strong></p>

<p><strong>Edit 2016-06-18: I’d orignally described this with arrays of maximum length $latex n$. But it works just as well with arrays of average length $latex n$, which is a stronger statement, so I’d rather use this one.</strong></p>

<p>Suppose I have $latex m$ sorted arrays of average length $latex n$. How quickly can I search to find the $latex k$th item in them?</p>

<p><a href="http://stackoverflow.com/a/26299986/1360429">This StackOverflow answer</a> mentions this problem offhandedly, but doesn’t clearly explain the algorithm, and it implies that the answer it’s thinking of is $latex O(m^2 \log(n)^2)$.</p>

<p>We can do better. You can modify quickselect to get an algorithm which takes $latex O(m \log(n) \log(m \cdot n))$ average case, and I suspect you can adapt <a href="https://en.wikipedia.org/wiki/Median_of_medians">median of medians</a> to get that time in the worst case.</p>

<p>The quickselect adaptation is pretty simple. We’re going to be do a simultaneous binary search on every array. For simplicity, let’s assume that all items in arrays are unique.</p>

<p>We’re going to need a <code class="highlighter-rouge">rank</code> method, which does a binary search to determine the number of items in an array smaller than its argument <code class="highlighter-rouge">x</code>. Here is such a method:</p>

<div class="language-ruby highlighter-rouge"><pre class="highlight"><code><span class="c1"># Returns the number of items in arr smaller than x.</span>
<span class="k">def</span> <span class="nf">rank</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">start_idx</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">end_idx</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">)</span>
  <span class="k">return</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">arr</span><span class="p">.</span><span class="nf">empty?</span>

  <span class="n">end_idx</span> <span class="o">=</span> <span class="n">arr</span><span class="p">.</span><span class="nf">length</span> <span class="k">if</span> <span class="n">end_idx</span><span class="p">.</span><span class="nf">nil?</span>

  <span class="c1"># this makes sense I promise, I'll explain later</span>
  <span class="k">return</span> <span class="n">arr</span><span class="p">.</span><span class="nf">length</span> <span class="k">if</span> <span class="n">start_idx</span> <span class="o">==</span> <span class="n">arr</span><span class="p">.</span><span class="nf">length</span>
  <span class="k">return</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">end_idx</span> <span class="o">==</span> <span class="mi">0</span>

  <span class="kp">loop</span> <span class="k">do</span>
    <span class="n">mid_idx</span> <span class="o">=</span> <span class="p">((</span><span class="n">start_idx</span> <span class="o">+</span> <span class="n">end_idx</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">).</span><span class="nf">floor</span>

    <span class="k">if</span> <span class="n">arr</span><span class="p">[</span><span class="n">mid_idx</span><span class="p">]</span> <span class="o">==</span> <span class="n">x</span>
      <span class="k">return</span> <span class="n">mid_idx</span>
    <span class="k">elsif</span> <span class="n">arr</span><span class="p">[</span><span class="n">mid_idx</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">x</span>
      <span class="k">return</span> <span class="n">start_idx</span> <span class="k">if</span> <span class="n">end_idx</span> <span class="o">-</span> <span class="n">start_idx</span> <span class="o">&lt;=</span> <span class="mi">1</span>
      <span class="n">end_idx</span> <span class="o">=</span> <span class="n">mid_idx</span>
    <span class="k">else</span>
      <span class="k">return</span> <span class="n">end_idx</span> <span class="k">if</span> <span class="n">end_idx</span> <span class="o">-</span> <span class="n">start_idx</span> <span class="o">&lt;=</span> <span class="mi">1</span>
      <span class="n">start_idx</span> <span class="o">=</span> <span class="n">mid_idx</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre>
</div>

<p>Now here’s how the select method is going to work. We’re going to start by setting up a <code class="highlighter-rouge">limits</code> variable. Normally in binary search, you need to store two variables, <code class="highlighter-rouge">start_idx</code> and <code class="highlighter-rouge">end_idx</code>. In our case, we’re going to store these two variables for every array we’re working with.</p>

<p>Every iteration, we’re going to randomly choose a pivot from the elements that haven’t been ruled out yet. Then we’re going to binary search all of the arrays to find the rank of the pivot in each of the arrays. We can add all these ranks together to find the rank of the pivot overall.</p>

<p>If the rank of the pivot is equal to <code class="highlighter-rouge">k</code>, then we return our pivot and stop recursing.</p>

<p>If the rank of the pivot is greater than <code class="highlighter-rouge">k</code>, our pivot is larger than the true result. So we can rule out every value which is larger than our pivot. For every array, we set its <code class="highlighter-rouge">end_idx</code> to the rank which it computed for the pivot.</p>

<p>If the rank of the pivot is smaller than k, then do the opposite: set the <code class="highlighter-rouge">start_idx</code> array to the rank array.</p>

<p>Here’s an implementation of that:</p>

<div class="language-ruby highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">quickselect_in_sorted_arrays</span><span class="p">(</span><span class="n">arrays</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">arrays</span><span class="p">.</span><span class="nf">first</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">if</span> <span class="n">arrays</span><span class="p">.</span><span class="nf">length</span> <span class="o">==</span> <span class="mi">1</span>

  <span class="n">arrays</span><span class="p">.</span><span class="nf">select!</span> <span class="p">{</span> <span class="o">|</span><span class="n">x</span><span class="o">|</span> <span class="n">x</span><span class="p">.</span><span class="nf">length</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="p">}</span>

  <span class="k">return</span> <span class="kp">nil</span> <span class="k">if</span> <span class="n">k</span> <span class="o">&gt;=</span> <span class="n">arrays</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="o">&amp;</span><span class="ss">:count</span><span class="p">).</span><span class="nf">reduce</span><span class="p">(</span><span class="o">&amp;</span><span class="p">:</span><span class="o">+</span><span class="p">)</span>

  <span class="c1"># In a single binary search, we have variables `start_idx`</span>
  <span class="c1"># and `end_idx`.</span>

  <span class="c1"># In this binary search, we need those variables for</span>
  <span class="c1"># every array. So we'll keep them in these arrays.</span>
  <span class="n">start_indexes</span> <span class="o">=</span> <span class="n">arrays</span><span class="p">.</span><span class="nf">map</span> <span class="p">{</span> <span class="mi">0</span> <span class="p">}</span>
  <span class="n">end_indexes</span> <span class="o">=</span> <span class="n">arrays</span><span class="p">.</span><span class="nf">map</span> <span class="p">{</span> <span class="o">|</span><span class="n">arr</span><span class="o">|</span> <span class="n">arr</span><span class="p">.</span><span class="nf">length</span> <span class="p">}</span>

  <span class="kp">loop</span> <span class="k">do</span>
    <span class="c1"># Randomly select an item from the viable candidates.</span>
    <span class="c1"># (This is obviously not an efficient implementation)</span>
    <span class="n">pivot</span> <span class="o">=</span> <span class="n">arrays</span><span class="p">.</span><span class="nf">map</span>
                  <span class="p">.</span><span class="nf">with_index</span> <span class="k">do</span> <span class="o">|</span><span class="n">arr</span><span class="p">,</span> <span class="n">idx</span><span class="o">|</span>
                    <span class="n">arr</span><span class="p">[</span><span class="n">start_indexes</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">end_indexes</span><span class="p">[</span><span class="n">idx</span><span class="p">]]</span>
                  <span class="k">end</span>
                  <span class="p">.</span><span class="nf">flatten</span>
                  <span class="p">.</span><span class="nf">sample</span>


    <span class="c1"># Find the rank of the pivot in every array.</span>
    <span class="n">pivot_ranks</span> <span class="o">=</span> <span class="n">arrays</span><span class="p">.</span><span class="nf">map</span><span class="p">.</span><span class="nf">with_index</span> <span class="k">do</span> <span class="o">|</span><span class="n">arr</span><span class="p">,</span> <span class="n">idx</span><span class="o">|</span>
      <span class="n">rank</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pivot</span><span class="p">,</span> <span class="n">start_indexes</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">end_indexes</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
    <span class="k">end</span>

    <span class="c1"># What is `pivot`'s overall rank in these arrays?</span>
    <span class="n">overall_rank_of_pivot</span> <span class="o">=</span> <span class="n">pivot_ranks</span><span class="p">.</span><span class="nf">reduce</span><span class="p">(</span><span class="o">&amp;</span><span class="p">:</span><span class="o">+</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">overall_rank_of_pivot</span> <span class="o">==</span> <span class="n">k</span>
      <span class="c1"># we're done! woohoo!</span>
      <span class="k">return</span> <span class="n">pivot</span>
    <span class="k">elsif</span> <span class="n">overall_rank_of_pivot</span> <span class="o">&gt;</span> <span class="n">k</span>
      <span class="c1"># our pivot was apparently too big.</span>

      <span class="c1"># On the plus side, we now know that wherever our binary</span>
      <span class="c1"># searches just finished, everything to the right of that</span>
      <span class="c1"># in that array is now guaranteed not to be the result.</span>
      <span class="n">pivot_ranks</span><span class="p">.</span><span class="nf">each_with_index</span> <span class="k">do</span> <span class="o">|</span><span class="n">rank</span><span class="p">,</span> <span class="n">idx</span><span class="o">|</span>
        <span class="n">end_indexes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">rank</span>
      <span class="k">end</span>
    <span class="k">else</span>
      <span class="c1"># If our pivot was too small, then we can rule out</span>
      <span class="c1"># everything to the left of those ranks.</span>
      <span class="n">pivot_ranks</span><span class="p">.</span><span class="nf">each_with_index</span> <span class="k">do</span> <span class="o">|</span><span class="n">rank</span><span class="p">,</span> <span class="n">idx</span><span class="o">|</span>
        <span class="n">start_indexes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">rank</span>
      <span class="k">end</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre>
</div>

<p>For full source code including some random testcases, <a href="https://gist.github.com/bshlgrs/14801efbb27d447fa7a2afba97ab70b4">look here</a>.</p>

<p>How fast is this method? The main loop costs $latex m \log(n)$ per iteration. How many times will we run it? Well, every time we run the iteration, we cut out all the elements which are on the wrong side of the result from our pivot. Worst case, we keep choosing the worst possible pivot and only ruling it out, which means we need to run that iteration once for every item in all of the arrays. This is $latex O(m^2 n \log(n))$.</p>

<p>But on average, we’ll cut a constant fraction of our search space out every time. So we should expect to have to do that iteration $latex \log(m\cdot n) = \log(m) + \log(n)$ times, for an overall time complexity of $latex O(m \log(n) \log(m \cdot n))$.</p>

<p>(Incidentally, when I was initially thinking about this, I thought we might get some speedup because our call to <code class="highlighter-rouge">rank</code> is going to be on a smaller and smaller section of its array every iteration throuhgh the loop. But I don’t think that’s true, because to get an asympotic decrease in the sum of a bunch of logarithms, you need to make your problem sizes decrease extremely quickly; exponentially decaying problem size doesn’t cut it. For example:</p>

<script type="math/tex; mode=display">O\left(\sum_{i=0}^n \log\left(2^i\right) \right) = O(\log(n)^2) = O\left(\sum_{i=0}^n \log\left(2^n\right) \right)</script>

<p>because</p>

<script type="math/tex; mode=display">O\left(\sum_{i=0}^n i \right) = O(n^2) = O\left(\sum_{i=0}^n n \right)</script>

<p>So I don’t think we can make that work.)</p>

<h2 id="further-questions">Further questions</h2>

<ul>
  <li>Can we generalize the <a href="https://en.wikipedia.org/wiki/Median_of_medians">median of medians</a> algorithm to get this to be guaranteed fast, rather than expected fast? The answer is almost certainly yes; I’ll probably try to prove it sometime.</li>
</ul>

  </div>

  <hr />

  <h2><a href="/2016/06/12/quickselect-lemma.html"> Quickselect on an unordered array and an order statistic tree</a></h2>

  <p class="post-meta"><time datetime="2016-06-12T00:00:00-07:00" itemprop="datePublished">Jun 12, 2016</time></p>

  <div class="shrink-headings">
    <p><strong>I did this work myself, so there are probably mistakes. I think the conclusion is right though.</strong></p>

<p>Suppose I have an <a href="https://en.wikipedia.org/wiki/Order_statistic_tree">order statistic tree</a> with $latex n$ elements and an unordered list with $latex m$ elements. Let’s say for the sake of simplicity that both are representing a set of items with no duplicates, and their intersection is empty.</p>

<p>If you want to find the $latex k$th element of the order statistic tree, you can do that in $latex O(log(n))$ time. And if you want to find the $latex k$th element of the array, you can use <a href="https://en.wikipedia.org/wiki/Quickselect">quickselect</a> and get it in $latex O(m)$ time. I want to find the $latex k$th smallest item in the disjoint union of these lists. How quickly can I do this?</p>

<p>You can do it trivially in $latex O(m + n)$ time, by flattening the order statistic tree (which I’ll call an OST from here onwards) onto the end of the array. Or you can add everything in the array to the OST and then query the OST, in $latex O(m \cdot \log(n + m))$ time.</p>

<p>I have found solutions that run in $latex O(m \cdot \log(n))$, $latex O(m + \log(m) \cdot \log(n))$, and $latex O(m + \log(n))$. The last of these is really complicated and annoying; the first two are pretty simple.</p>

<h2 id="order-statistic-trees">Order statistic trees</h2>

<p>I’m going to write code in Ruby, in which the <code class="highlighter-rouge">filter</code> method is stupidly named <code class="highlighter-rouge">select</code>. OSTs are usually presented with a method called <code class="highlighter-rouge">select(k)</code> which finds the $latex k$th smallest element. In this post I’m going to use the method name <code class="highlighter-rouge">find_kth_smallest</code> instead.</p>

<p>I’m going to assume that my OSTs have the following methods:</p>

<ul>
  <li><code class="highlighter-rouge">smallers</code>: returns the left subtree</li>
  <li><code class="highlighter-rouge">largers</code>: returns the right subtree</li>
  <li><code class="highlighter-rouge">pivot</code>: returns the value of the root node</li>
  <li><code class="highlighter-rouge">count</code>: returns the number of items in the node</li>
  <li><code class="highlighter-rouge">find_kth_smallest(k)</code>: as discussed above</li>
  <li><code class="highlighter-rouge">rank(x)</code>: finds the number of elements in the OST smaller than <code class="highlighter-rouge">x</code>. This takes $latex O(\log(n))$ in an OST.</li>
  <li><code class="highlighter-rouge">split_on_left_by_value(x)</code>: returns a new tree with only the items in the OST which are less than <code class="highlighter-rouge">x</code>. If our OSTs are immutable, this only takes $latex\log(n)$ time.</li>
  <li><code class="highlighter-rouge">split_on_right_by_value(x)</code>: like <code class="highlighter-rouge">split_on_left_by_value</code>, but the other side.</li>
</ul>

<h2 id="standard-quickselect">Standard quickselect</h2>

<p>Just for reference, here’s an unoptimized implementation of quickselect. This has average case performance $latex O(n)$.</p>

<div class="language-ruby highlighter-rouge"><pre class="highlight"><code><span class="c1"># assumes that the list has all unique elements</span>
<span class="c1"># returns the same thing as array.sort[n]</span>
<span class="k">def</span> <span class="nf">quickselect</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
  <span class="c1"># choose a random pivot</span>
  <span class="n">pivot_element</span> <span class="o">=</span> <span class="n">array</span><span class="p">.</span><span class="nf">sample</span>

  <span class="n">smallers</span> <span class="o">=</span> <span class="n">array</span><span class="p">.</span><span class="nf">select</span> <span class="p">{</span> <span class="o">|</span><span class="n">x</span><span class="o">|</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="n">pivot_element</span> <span class="p">}</span>
  <span class="n">largers</span> <span class="o">=</span> <span class="n">array</span><span class="p">.</span><span class="nf">select</span> <span class="p">{</span> <span class="o">|</span><span class="n">x</span><span class="o">|</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="n">pivot_element</span> <span class="p">}</span>

  <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="n">smallers</span><span class="p">.</span><span class="nf">length</span>
    <span class="n">quickselect</span><span class="p">(</span><span class="n">smallers</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
  <span class="k">elsif</span> <span class="n">n</span> <span class="o">==</span> <span class="n">smallers</span><span class="p">.</span><span class="nf">length</span>
    <span class="n">pivot_element</span>
  <span class="k">else</span>
    <span class="n">quickselect</span><span class="p">(</span><span class="n">largers</span><span class="p">,</span> <span class="n">n</span> <span class="o">-</span> <span class="n">smallers</span><span class="p">.</span><span class="nf">length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre>
</div>

<p>This has average case $latex O(n)$ performance because the recurrence relation is:</p>

<script type="math/tex; mode=display">f(n) = f\left(\frac{n}2\right) + n</script>

<h2 id="modified-quickselect-attempt-1-latex-om-cdot-logn">Modified quickselect, attempt 1: $latex O(m \cdot \log(n))$</h2>

<p>Let’s modify this to also use an OST.</p>

<div class="language-ruby highlighter-rouge"><pre class="highlight"><code><span class="c1"># OST has size n</span>
<span class="c1"># array has size m</span>
<span class="c1"># this returns the same thing as (array + ost.to_a).sort[k]</span>
<span class="k">def</span> <span class="nf">double_quickselect_v1</span><span class="p">(</span><span class="n">ost</span><span class="p">,</span> <span class="n">array</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
  <span class="n">smallers</span> <span class="o">=</span> <span class="n">arr</span><span class="p">.</span><span class="nf">select</span> <span class="p">{</span> <span class="o">|</span><span class="n">x</span><span class="o">|</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="n">ost</span><span class="p">.</span><span class="nf">pivot</span> <span class="p">}</span>
  <span class="n">largers</span> <span class="o">=</span> <span class="n">arr</span><span class="p">.</span><span class="nf">select</span> <span class="p">{</span> <span class="o">|</span><span class="n">x</span><span class="o">|</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="n">ost</span><span class="p">.</span><span class="nf">pivot</span> <span class="p">}</span>

  <span class="n">number_of_smaller_things</span> <span class="o">=</span> <span class="n">smallers</span><span class="p">.</span><span class="nf">length</span> <span class="o">+</span> <span class="n">ost</span><span class="p">.</span><span class="nf">smallers</span><span class="p">.</span><span class="nf">count</span>

  <span class="k">if</span> <span class="n">number_of_smaller_things</span> <span class="o">&gt;</span> <span class="n">k</span>
    <span class="n">double_quickselect_v1</span><span class="p">(</span><span class="n">smallers</span><span class="p">,</span> <span class="n">ost</span><span class="p">.</span><span class="nf">smallers</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
  <span class="k">elsif</span> <span class="n">number_of_smaller_things</span> <span class="o">==</span> <span class="n">k</span>
    <span class="n">ost</span><span class="p">.</span><span class="nf">pivot</span>
  <span class="k">else</span>
    <span class="n">double_quickselect_v1</span><span class="p">(</span><span class="n">largers</span><span class="p">,</span> <span class="n">ost</span><span class="p">.</span><span class="nf">largers</span><span class="p">,</span> <span class="n">k</span> <span class="o">-</span> <span class="n">number_of_smaller_things</span><span class="p">)</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre>
</div>

<p>Every time we make a recursive call, our order statistic tree halves in size. Our array might not get smaller though: eg if everything in your array is smaller than everything in your OST. Our OST has depth $latex \log(n)$, and in the worst case you need to iterate over everything in your array every time. So this is $latex O(m \cdot \log(n))$.</p>

<p>Can we do better? I think we can. Intuitively, it seems like this algorithm works to shrink the OST as fast as possible, and not really worry about the array. But the array is where most of the cost comes from. So we should try to organize this algorithm so that instead of halving the size of the OST every time, it halves the size of the array every time.</p>

<h2 id="modified-quickselect-attempt-2-latex-om--logm-cdot-logn">Modified quickselect, attempt 2: $latex O(m + \log(m) \cdot \log(n))$</h2>

<p>Instead of using the OST’s pivot, let’s pivot on a randomly selected member of the array, like in normal quickselect. This means that the array is probably going to shrink with every recursive call.</p>

<div class="language-ruby highlighter-rouge"><pre class="highlight"><code><span class="c1"># OST has size n</span>
<span class="c1"># array has size m</span>
<span class="c1"># this returns the same thing as (array + ost.to_a).sort[k]</span>
<span class="k">def</span> <span class="nf">double_quickselect_v2</span><span class="p">(</span><span class="n">ost</span><span class="p">,</span> <span class="n">array</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
  <span class="n">pivot_element</span> <span class="o">=</span> <span class="n">arr</span><span class="p">.</span><span class="nf">sample</span>
  <span class="n">smallers</span> <span class="o">=</span> <span class="n">arr</span><span class="p">.</span><span class="nf">select</span> <span class="p">{</span> <span class="o">|</span><span class="n">x</span><span class="o">|</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="n">pivot_element</span> <span class="p">}</span>
  <span class="n">largers</span> <span class="o">=</span> <span class="n">arr</span><span class="p">.</span><span class="nf">select</span> <span class="p">{</span> <span class="o">|</span><span class="n">x</span><span class="o">|</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="n">pivot_element</span> <span class="p">}</span>

  <span class="n">number_of_smaller_things</span> <span class="o">=</span> <span class="n">smallers</span><span class="p">.</span><span class="nf">length</span> <span class="o">+</span> <span class="n">ost</span><span class="p">.</span><span class="nf">rank</span><span class="p">(</span><span class="n">pivot_element</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">number_of_smaller_things</span> <span class="o">&gt;</span> <span class="n">k</span>
    <span class="n">double_quickselect_v2</span><span class="p">(</span><span class="n">smallers</span><span class="p">,</span>
                        <span class="n">ost</span><span class="p">.</span><span class="nf">split_on_right_by_value</span><span class="p">(</span><span class="n">pivot_element</span><span class="p">),</span>
                        <span class="n">k</span><span class="p">)</span>
  <span class="k">elsif</span> <span class="n">number_of_smaller_things</span> <span class="o">==</span> <span class="n">k</span>
    <span class="n">ost</span><span class="p">.</span><span class="nf">pivot</span>
  <span class="k">else</span>
    <span class="n">double_quickselect_v2</span><span class="p">(</span><span class="n">largers</span><span class="p">,</span>
                        <span class="n">ost</span><span class="p">.</span><span class="nf">split_on_left_by_value</span><span class="p">(</span><span class="n">pivot_element</span><span class="p">),</span>
                        <span class="n">k</span> <span class="o">-</span> <span class="n">number_of_smaller_things</span><span class="p">)</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre>
</div>

<p>So now the array is going to shrink on average by a factor of 2 every recursive call, but in the worst case the tree will stay the same size every time. So we now expect to $latex \log(m)$ recursive calls, for a total cost of $latex O(m + \log(m) \cdot \log(n))$.</p>

<p>(Incidentally, calling <code class="highlighter-rouge">ost.split_on_left_by_value</code> doesn’t affect the asymptotic runtime of this function, because this only decreases the size of <code class="highlighter-rouge">ost</code> by a constant multiplier in expectation, and it doesn’t cause <code class="highlighter-rouge">ost.rank(pivot_element)</code> to run asymptotically faster.)</p>

<p>Okay, this is better. But can we improve it even more?</p>

<h2 id="sketch-of-a-latex-om--logn-solution">Sketch of a $latex O(m + \log(n))$ solution</h2>

<p>I’m pretty sure I have an optimal solution, but it’s really complicated and annoying.</p>

<p>The problem was that in the previous algorithms, sometimes I computed expensive things for the data structures without any guarantee that they’d end up smaller. This time, I want to either compute tertiles for a data structure and shrink it, or ignore it.</p>

<p>For this to work, we’re going to need our OST to be a <a href="https://en.wikipedia.org/wiki/Weight-balanced_tree">weight-balanced tree</a>. Let’s set $latex \alpha = \frac 14$. (Actually, I think this algorithm works with non-weight-balanced trees, but I don’t know how to prove the time bound without the weight balance.)</p>

<p>Here’s how: At the start of every recursive call, we look at the relative sizes of the two data structures. If one is much larger than the other, we’re going to shrink the large one and ignore the small one. If they’re within a factor of 2 of each other, we’re going to call the expensive methods on both then shrink one of them.</p>

<p>If you want the gory details, read on.</p>

<h3 id="case-1-one-is-much-larger-than-the-other">Case 1: one is much larger than the other</h3>

<p>Suppose one data structure has more than three times as many things in it as the other one does. Let’s call the two data structures <code class="highlighter-rouge">Big</code> and <code class="highlighter-rouge">Small</code>. <code class="highlighter-rouge">Big</code> has size $latex b$, <code class="highlighter-rouge">Small</code> has size $latex s$.</p>

<p>Suppose we have 100 things in <code class="highlighter-rouge">Big</code> and 10 things in <code class="highlighter-rouge">Small</code>. We want to find the 15th largest thing in <code class="highlighter-rouge">Big ++ Small</code>. Let’s call the result $latex x$.</p>

<p>$latex x$ can’t be more than <code class="highlighter-rouge">Big.find_kth_smallest(15)</code>, because by definition there are 15 things in <code class="highlighter-rouge">Big</code> less than that.</p>

<p>And $latex x$ can’t be less than <code class="highlighter-rouge">Big.find_kth_smallest(5)</code>, because there are only 5 things in <code class="highlighter-rouge">Big</code> less than that, and there are only 10 things in Small.</p>

<p>So if we’re looking for the <code class="highlighter-rouge">k</code>th item in <code class="highlighter-rouge">Big ++ Small</code>, we can discard everything bigger than <code class="highlighter-rouge">Big.find_kth_smallest(k)</code>, and everything smaller than <code class="highlighter-rouge">Big.find_kth_smallest(k + s)</code>.</p>

<h4 id="case-1a-the-array-is-larger">Case 1a: the array is larger</h4>

<p>If the array is the larger data structure, then we do this discard by calling quickselect twice and copying everything between the two results to a new array. This takes $latex O(m)$ time, and the resulting array is at most size $latex s$. So we made our array half its original size.</p>

<h4 id="case-1b-the-ost-is-larger">Case 1b: the OST is larger</h4>

<p>If the tree is the larger data structure, then things are somewhat more annoying, because we only want to take constant time.</p>

<p>Selecting exactly the first $latex k$ things in an OST takes $latex \log(n)$ time. I’m going to suggest that instead of selecting exactly the first $latex k$ things, we should go a few layers deep in our OST and then delete only the nodes which we know we can safely delete.</p>

<p>Because we’re using weight-balanced trees with a weight balancing factor of $latex \frac 14$, we might need to go down maybe 3 layers in order to get a node with enough weight that deleting it deletes half the weight that you’d be able to delete if you called <code class="highlighter-rouge">split_on_left_by_value</code>. (I’m not sure about the number 3 being correct, but I think this is true for some constant.)</p>

<p>We could safely remove $latex \frac 12$ of the tree if we used the normal split methods. We’re going to remove more than half of that, so at worst our tree will end up $latex\frac 34$ of its original size.</p>

<p>So in both cases, we end up with the bigger data structure being a constant factor smaller.</p>

<h3 id="case-2-the-data-structures-are-a-similar-size">Case 2: the data structures are a similar size</h3>

<p>Oh man, this gets messy. I’m going to call this bit an “algorithm sketch”, because then you can’t criticise me for being handwavy.</p>

<p>Get approximate tertiles from the OST and exact tertiles from the array. This takes $latex O(m)$ time for the array and $latex O(1)$ time for the OST.</p>

<p>Then you compare these two inter-tertile ranges. There are three cases: they can intersect, they can be disjoint, or one can be inside the other. In each of these cases, based on your value of $latex k$ you can rule out at least a third of at least one of the two data structures. This is just a massive mess of cases. Here’s a diagram of one way it can play out when the ranges intersect:</p>

<p><img src="/img/ost_diagram.jpg" alt="diagram" /></p>

<p>This is a diagram of what happens when one data structure has 30 items and the other has 60 items. It contains all of the different cases for $latex k$. For example, when $latex k$ is 35, then we can discard the upper and lower thirds of the 30 item data structure, and we can discard the upper third of the 60 item data structure.</p>

<p>You can draw similar diagrams for the other cases.</p>

<p>This part is the sketchiest part of the whole algorithm. I’m pretty sure that you can always decrease at least one of the data structures by one third. I’m not sure if you can always shrink both of them. I’m not sure how much you can shrink the OST in constant time; I’m pretty sure you can do at least $latex \frac 16$, and I think that for any fraction less than $latex \frac 13$, you can choose a node depth such that you can always cut that fraction out in constant time.</p>

<h3 id="runtime-of-this-solution">Runtime of this solution</h3>

<p>If one of the data structures starts out much larger than the other one, it will shrink until they’re similar sizes. This takes $latex O(m)$ time for the array and $latex O(\log(n))$ time for the OST.</p>

<p>Once they’re the same size, I think that at least one of them will both shrink by one third every time. So we have the recurrence relation:</p>

<script type="math/tex; mode=display">f(n, m) = f \left( \frac {2n}3, \frac {2m}3\right) + m + 1</script>

<p>which evaluates to $latex \log(n) + m$.</p>

<h2 id="conclusion">Conclusion</h2>

<p>So we can do quick select on an OST and array at the same time in $latex O(m + \log(n))$.</p>

<p>My work here leaves a lot to be desired. Most obviously, my fastest algorithm is extremely complicated and inelegant; I bet that can be simplified.</p>

  </div>

  <hr />

  <h2><a href="/2016/06/02/say.html"> Not thinking of things I can't say</a></h2>

  <p class="post-meta"><time datetime="2016-06-02T00:00:00-07:00" itemprop="datePublished">Jun 2, 2016</time></p>

  <div class="shrink-headings">
    <p>I noticed recently that I usually don’t think of thoughts which I’m not going to be able to say for political correctness reasons. Occasionally when I talk to people who don’t care about offending progressives, they say really insightful things which I would never have thought of on my own, because my brain just blocks those thoughts out before I can think them.</p>

<p>This is annoying, because I’d rather think of things like that and not say them publicly than not think of them at all.</p>

<p>I think the main cause of this is that I do a lot of my thinking while talking to people about things, and if certain kinds of discussion are stifled, I don’t get practice thinking about them.</p>

<p>This has a few implications. Firstly, it means that efforts to stifle offensive thoughts concern me somewhat more than they did previously, because I am more concerned that restricting speech restricts thoughts. Secondly, it makes me think more that private spaces for conversations are important. Third, it makes me really glad for circle-jerking EAs who are privately enjoy biting bullets and saying purposefully controversial things—I’d previously thought of that as harmless fun, but now I think that it might have the important function of countering the natural push towards orthodoxy.</p>

<hr />

<p><a href="https://www.facebook.com/bshlgrs/posts/10207784018613166">view comments on Facebook</a></p>

  </div>

  <hr />

  <h2><a href="/2016/05/29/explicit.html"> Optimize dating for non-interference with platonic relationships</a></h2>

  <p class="post-meta"><time datetime="2016-05-29T00:00:00-07:00" itemprop="datePublished">May 29, 2016</time></p>

  <div class="shrink-headings">
    <p>[content warning—I make a lot of claims that certain ways of hitting on people are much better than other ways. If you have a tendency to freak out about whether you’re a terrible person for being sexually attracted to people, maybe don’t read this.]</p>

<p>It’s often hard for men and women to hang out with each other non-romantically. This is terrible! Terrible! So terrible that reducing this problem should be a major priority for progressive subcultures. I think we can make progress by pushing for better norms about hitting on people. Let’s look at some common dating advice:</p>

<p>“When you’re asking a girl out, don’t explicitly ask her on a date. Instead, ask her if she wants to get coffee with you. It’s obvious that you’re asking her on a date, but this way if she wants to reject you she can do it more subtly and it’s less awkward for everyone involved.”</p>

<p>I think this is absolutely terrible advice! Not for the man who receives that advice, but for the society where that’s the social norm. Because sometimes I meet women and I think they’re interesting, and I would love to meet them again to hang out with them sometime. What do I do? I sure as hell can’t ask them to meet up for coffee or a meal.</p>

<p>So this faux ambiguity ends up creating a situation where it is very hard for men and women to spend time with each other.</p>

<p>This is particularly terrible in a professional context, especially one like programming where hanging out with people is really valuable, and there are relatively few women around. It’s not so hard for me if I can only meet up with male friends and talk about data structures—I’ve only lost 20% or whatever of my total conversational options. It’s much harder for the women who lose 80%.</p>

<p>(one argument you could make: “well if p is the proportion of women who are in a field, and you can’t hang out with people of the other gender, the total hangout opportunities = p**2 + (1-p)**2, which is maximized at p=0 and p=1, therefore we want to segregate everything as much as possible.”)</p>

<p>I’ve heard women talk about how one factor making career development harder for them is that it’s much harder for them to get dinner with their managers or peers without it seeming weird.</p>

<p>Even without that particular gender imbalance element, this is bad and worth fighting against. But I think that as a society and as a subculture, we can make choices which make this less of a problem. Even better, I don’t think we need to totally overhaul society to improve this: as long as individual men are known for having clear and unproblematic behaviors, women don’t have this problem around them.</p>

<hr />

<p>So here goes. Here are some rules which I think might reduce these problems.</p>

<ul>
  <li>When you ask people out, always ask them out extremely explicitly. “Would you like to go on a date with me next week” is a good sentence to use. (If you’re on a dating website or other environment where everyone is forgoing the ability to make plausibly-non-romantic connections, you don’t have to follow this rule.)</li>
  <li>If you specifically invite someone to hang out with you and it wasn’t you asking them out, never ask them out or proposition them while you’re hanging out. Relatedly (and this should be obvious but apparently isn’t), don’t hit on people in situations where they can’t get away from you without awkwardness.</li>
  <li>It’s fine to ask people out over Facebook messages or email. (In fact, it’s probably better to ask people out asynchronously than putting them on the spot by asking in person, especially if it’s someone you already know.)</li>
</ul>

<p>The goal of the first is to make it easier to hang out with people platonically. The goal of the second is to establish common knowledge that if I invite you to hang out with me sometime, I’m not going to hit on you and cause you to awkwardly have to deflect my advances and consider leaving.</p>

<p>I feel pretty good about following these rules in my current context. I’ve pretty much always followed that first rule.</p>

<p>One objection to the first rule is that it makes it somewhat more awkward for the rejectee. I think that this is better than the problems caused by ambiguity. And you can always add the ambiguity back in by asking, for example, for a date at a specific time; they can reject you by saying they’re busy then if they want. (Incidentally, I don’t think that what makes this less awkward is the faux ambiguity. I think that it’s just less awkward because you’ve set it up so that you’re basically supplied them with a rejection sentence if they want to say no; this means they’re less likely to be caught flat-footed and awkwardly not know what to say.) Alternatively or additionally, you can ask people out online, which reduces the pressure further.</p>

<p>I broke that second rule several times at college, and I really enjoyed that. Hanging out with people late at night and knowing that it might or might not lead to making out was really fun. But college was a much better place for that than adult life. At college you can usually go home, which kind of defuses some of the discomfort. I’m still somewhat confused by my intuitions here—I definitely feel that ambiguity was less of a problem at college than it is in adult life. (I also feel like this is slightly less of a problem within rationalism than in general society—maybe it’s partially because college and rationalism are both promiscuous subcultures? Maybe it’s because rationalists are better at average at talking through some kinds of problems? Maybe it’s because college girls are less cynical and for whatever reason seem to be put off somewhat less by these problems than other women, in my experience?)</p>

<hr />

<p>If the current norm is bad, why is it a stable equilibrium? Partially this problem is worse now than it used to be, because women started joining the workforce recently enough that society might not have shifted properly yet. And partially it’s because the costs are mostly felt by women (and somewhat, men scrupulous enough to worry about imposing them). It’s slightly convenient for individual men to have some ambiguity when they’re asking out women, or asking them to hang out; it’s inconvenient for women but they aren’t the ones making the decision so it happens anyway.</p>

<p>I think there’s legitimately an opportunity for a community to talk about this a lot and come up with significantly better norms about it. Communities which I’m supposedly a part of—reckon we should do this?</p>

<p>[I wrote this after talking to Claire Zabel about this a lot over the last few weeks; many of the ideas are hers.]</p>

<hr />

<p><a href="https://www.facebook.com/bshlgrs/posts/10207777395247586">view comments on Facebook</a></p>

  </div>

  <hr />

  <h2><a href="/2016/05/29/flinching.html"> Flinching away from hard things</a></h2>

  <p class="post-meta"><time datetime="2016-05-29T00:00:00-07:00" itemprop="datePublished">May 29, 2016</time></p>

  <div class="shrink-headings">
    <p>I have a strong reflex to not do complicated things when I’m writing code—I flinch away and try really hard to avoid them. I think this reflex often serves me well, because complicated code is a pain to maintain and in real life you usually don’t need it. When I watch other people code, I often see them start down a complicated path to solve a problem, and then persevere through it. When faced with the same problems as them, I’m much more inclined to start down a complicated path, then realize it’s going to be complicated and reflexively give up. Most problems that I run across actually have relatively simple solutions, so this serves me well: I end up flailing for longer at the start, but then I end up with simpler code than I would have had otherwise.</p>

<p>But sometimes programming tasks are actually complicated and difficult. And my reflex against doing hard things really serves me wrong there. I find myself procrastinating and circling around the problem. I start attempts and then give up on them. Eventually I notice that I’m not getting anywhere and I need to just suck it up, get a coffee and sit in a quiet room and actually plough through it. But I’m sure I’m much worse at this than many other programmers who are as good as I am at easy things.</p>

<p>For this reason, I’ve never implemented in-place quick sort, or a correct alpha-beta pruned minimax, or any kind of self balancing binary search tree. I’ve started all of them, but I always give up. I’m pretty sure that the most complicated small-scale code I’ve written in my life was written in my technical interviews at Apple, because they asked hard questions and they were watching me so I was motivated to not give up. (But even that pressure wasn’t enough—towards the end of one of the interviews, my interviewer asked if I could modify the code I’d written to handle a more general problem. I basically said “I could, but I really don’t want to” and half-assedly tried to evade the question.)</p>

<hr />

<p><a href="https://www.facebook.com/bshlgrs/posts/10207724688649954">view comments on Facebook</a></p>

<p>Satvik Beri made a <a href="https://www.facebook.com/bshlgrs/posts/10207748156956647?comment_id=10207748263919321&amp;comment_tracking=%7B%22tn%22%3A%22R0%22%7D">particularly great comment</a>:</p>

<blockquote>
  <p>I try to maintain separate mental modes, searching for simple solutions vs. implementing tricky ones, with a trigger to switch–if I’m stuck on a problem and it genuinely looks like there’s no easy solution, I mutter “I ain’t afraid of nothin’” (stolen from Claude Shannon: https://www.cs.utexas.edu/~dahlin/bookshelf/hamming.html) and dive in.</p>
</blockquote>

  </div>

  <hr />


<p><a href="/posts">All posts</a></p>

<p><a href="/feed.xml">RSS feed</a></p>

<script>
$(function() {
  $(".shrink-headings").map(function(idx, div) {
    $(div).html(
      $(div)
        .html()
        .replace(/<h4/g, "<h5")
        .replace(/<h3/g, "<h4")
        .replace(/<h2/g, "<h3")
    )
  })
})
</script>


      <hr/>

<div class="PageNavigation">
  
  
</div>

    </div>
    <div class="col-sm-3 col-sm-offset-1">
      <img src="https://scontent-sjc2-1.xx.fbcdn.net/hphotos-xtp1/t31.0-8/11154688_10205041372168719_3725604149367069581_o.jpg" class="img-responsive" alt="Picture of Buck">
      
<hr/>
<a class="arrow" href="/"><strong>Buck</strong></a>
<ul>
  <li><a class="arrow" href="/about">About</a>
    <ul>
      <li><a href="http://triplebyte.com?ref=bshlgrs.github.io">Triplebyte</a></li>
    </ul>
  </li>
  <li>Links
    <ul>
      <li>
          <a class="arrow" href="http://github.com/bshlgrs">GitHub</a>
      </li>
      <li>
          <a class="arrow" href="mailto:bshlegeris@gmail.com">Email</a>
      </li>
      <li>
          <a class="arrow" href="http://www.facebook.com/bshlgrs">Facebook</a>
      </li>
      <li>
          <a class="arrow" href="http://lnkd.in/bnBJ6EF">LinkedIn</a>
      </li>
      <li>
          <a class="arrow" href="/resume.pdf">Resume</a>
      </li>
    </ul>
  </li>
  <li><a class="arrow external" href="https://docs.google.com/forms/d/1SOombLPHlKIMut-wJzIRg7DGdJjh9PJV4yAkrmTXKn4/viewform?usp=send_form">Anonymous feedback</a></li>

  <li><a href="/posts" class="arrow">Blog</a>
    <ul>
      
        <li>
          <a class="arrow" href="/2016/06/22/ctci.html">Studying for startup interviews with 'Cracking the Coding Interview'</a>
        </li>
      
        <li>
          <a class="arrow" href="/2016/06/16/kth-richest.html">'Who is the kth richest person with age between x and y'</a>
        </li>
      
        <li>
          <a class="arrow" href="/2016/06/16/generalized-multi-quickselect.html">Generalized multi-quickselect</a>
        </li>
      
        <li>
          <a class="arrow" href="/2016/06/15/multi-sorted-array-quickselect.html">Quickselect on multiple sorted arrays</a>
        </li>
      
        <li>
          <a class="arrow" href="/2016/06/12/quickselect-lemma.html">Quickselect on an unordered array and an order statistic tree</a>
        </li>
      
        <li>
          <a class="arrow" href="/2016/06/02/say.html">Not thinking of things I can't say</a>
        </li>
      
        <li>
          <a class="arrow" href="/2016/05/29/explicit.html">Optimize dating for non-interference with platonic relationships</a>
        </li>
      
        <li>
          <a class="arrow" href="/2016/05/29/flinching.html">Flinching away from hard things</a>
        </li>
      
    </ul>
  </li>
  <li>
      <a class="arrow" href="/cute">Pictures of me</a>
  </li>
</ul>

    </div>
  </div>
</div>




    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Buck Shlegeris</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>Buck Shlegeris</li>
          <li><a href="mailto:bshlegeris@gmail.com">bshlegeris@gmail.com</a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/bshlgrs"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">bshlgrs</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/bshlgrs"><span class="icon icon--twitter"><svg viewBox="0 0 16 16"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">bshlgrs</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>Website of Buck Shlegeris.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-52980069-1', 'auto');
  ga('send', 'pageview');

</script>

</html>

