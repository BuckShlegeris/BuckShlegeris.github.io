<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Buck Shlegeris</title>
  <meta name="description" content="Website of Buck Shlegeris.
">


  <link rel="stylesheet" href="/bootstrap.css">
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://bshlgrs.github.io/">
  <link rel="alternate" type="application/rss+xml" title="Buck Shlegeris" href="http://bshlgrs.github.io/feed.xml">
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$latex', '$'] ],
        displayMath: [ ['$$', '$$']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      messageStyle: "none",
      "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
    });
  </script>
  <script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
  <script src="/jquery.js"></script>
  <script type="text/babel" src="/main.js"></script>
  
</head>


  <body>

    

    <div class="container">
  <div class="row">
    <div class="col-sm-7 col-sm-offset-1 markdownify">
      
      <p class="post-meta"><time datetime="1969-12-31T16:00:00-08:00" itemprop="datePublished"></time></p>

      <hr/>

      <h1>Buck Shlegeris</h1>

<div class="lead">
<p>I am a software engineer from Australia. I have lived in San Francisco for most of the last three years. I'm interested in data structures and effective altruism.</p>

<p>Here are some things that I've written recently:</p>
</div>


  <h2><a href="/2016/07/02/hash-ordered-treaps.html"> Hash-ordered treaps</a></h2>

  <p class="post-meta"><time datetime="2016-07-02T00:00:00-07:00" itemprop="datePublished">Jul 2, 2016</time></p>

  <div class="shrink-headings">
    <p>Hash-ordered treaps are a cool kind of binary search tree. They have the neat property that there mapping from ordered sets to hash-ordered treaps is one-to-one and onto. That is, for every ordered set, there’s exactly one valid hash-ordered treap which represents it.</p>

<p>So what’s a hash-ordered treap? Well, choose your favorite hash function and call it h. A hash-ordered treap is a binary search tree which follows one additional restriction: for every parent and child, h(value of parent) &gt; h(value of child).</p>

<p>(It’s called a hash-ordered treap because as well as being a tree, it’s also a heap ordered on the hash of the node value.)</p>

<p>There’s exactly one hash-ordered treap for a given ordered set. This wasn’t totally obvious to me at first, but the proof is pretty simple. Suppose you have a ordered set. One of its values must have the highest hash value. That value is going to be the root of the tree. Everything in the ordered set less than the root is going to be in a hash-ordered treap on the left, and everything greater than the root is going to be in a hash-ordered treap on the right. So by structural induction, QED.</p>

<p>Insertion is pretty simple: you just search down for the right place to insert as usual, then you do tree rotations up to restore the heap ordering property. I think this takes an average of O(1) time if you’re inserting random keys into random treaps, for the same reason that heap insertion is sort of average O(1) time. (But I made that proof up myself, so it might be wrong. Worst case it’s O(log(n)), so no big deal if so.)</p>

<p>This nice isomorphism between ordered sets and hash-ordered treaps is useful when you want to be able to build BSTs separately places and later merge them together, taking advantage of the fact that the trees will be very similar if
they have similar elements. I first saw this used in <a href="http://arxiv.org/abs/1301.3388">this paper</a>.</p>

  </div>

  <hr />

  <h2><a href="/2016/06/30/triplebyte.html"> You should work at Triplebyte</a></h2>

  <p class="post-meta"><time datetime="2016-06-30T00:00:00-07:00" itemprop="datePublished">Jun 30, 2016</time></p>

  <div class="shrink-headings">
    <p>Triplebyte, the startup where I work, is hiring. We’re looking for engineers, a writer, a UX designer, and some generalist roles.</p>

<p>I think Triplebyte is a great place to work. In particular, I think that <strong>if you’re an EA, working at Triplebyte is a great opportunity for you if you would otherwise be earning to give and developing career capital.</strong> Here’s why.</p>

<p>I’ve learned an enormous amount since I started working here. I have a lot of freedom in what I do and how I do it. For example, my first major project had a significant UI component, and I wanted to do it in React; my CTO didn’t know React but was fine with me bringing it into the site. My second project was a complicated backend web project which involved, among other things, learning how to take care of a bunch of complicated servers on AWS. And my current project is essentially a interviewing research project: I’m developing a coding problem very different to everything we currently ask, and currently I’m collecting data to determine whether it correlates with our other measurements well enough that we should use it.</p>

<p>Empiricism is core to what we do. I’ve never before worked in a setting which puts as much work into statistical analysis of its various projects. Almost every task I have involves coming up with a hypothesis that if we work on some particular thing, we’ll improve some particular metric. I then build whatever software is required. After a while, we do a statistical analysis to determine whether my project has a positive effect. If it doesn’t, we modify it or abandon it.</p>

<p>The core skill I’m learning is the extremely useful general skill of figuring out how to make progress on hard and confusing problems, given incomplete information and significant costs to gathering data. I am super glad to be practicing this. This will be extremely useful to me regardless of what I end up doing long term—most obviously, it’s a useful skill for many kinds of direct work, many kinds of research, and entrepreneurship.</p>

<p>I think Triplebyte is an unusually good opportunity to develop these skills for a few reasons. To start with, as companies get bigger, they have more of an idea of what they’re doing, so you don’t get to work on problems with such large scope. Especially if you’re fundamentally just an empirically minded engineer—at most companies you’ll end up just working on engineering specific solutions, rather than broadly investigating the space of solutions. Among small companies, I don’t think many have founding teams as experienced, or engineers as good (I feel qualified to say this because I’ve interviewed a lot of engineers, and my coworkers are generally stronger programmers.)</p>

<p>(Triplebyte also has some downsides. Most obviously, engineers spend like 20 hours a week interviewing people. This is sort of a pain. On the other hand, I’ve certainly gotten something useful out of it: I have a way better understanding of a diverse range of topics in computer science now, and I’m somewhat better at communicating about some things, and I’ve learned that lots of people sound really smart when they talk about things they’ve done, then absolutely go to pieces when you ask them for technical details. I have gotten a much better feel for the ways and the extent that programmers vary.)</p>

<p>One of the projects I’m working on at the moment is something which I came up with on a whim one evening and coded a prototype of—my coworkers liked it, so I’m now building it into the main site. You don’t get to do this kind of thing at most companies.</p>

<p>The company culture is currently very well suited to EAs and rationalists: one reason I want to recruit my friends is that I’d like to keep it that way.</p>

<p>We’re hiring for the following roles (more info <a href="https://triplebyte.com/careers">here</a>):</p>

<ul>
  <li>Software engineer. You need to be good at thinking and programming. You need really broad knowledge of computer science, because you need to be able to talk intelligently about anything that your interviewee might want to talk about. You need to be friendly, because you spend a bunch of time interviewing.</li>
  <li>Writer. We would love to hire someone to spend all their time taking our data and turning it into blog posts. If you like writing about data, this would be a great job for you.</li>
  <li>Designer/UX. We need someone to design all our user interfaces and do all our other visual design work.</li>
  <li>Talent manager. This is a person who handles all our interaction with our candidates. You need to be really organized, good at interacting with people (especially software engineers), and you need to be excited about doing experiments and using data to improve how we manage candidates.</li>
  <li>Other generalist roles: Product Operations and an Operation Manager</li>
</ul>

<p>Get in touch with me if you’re interested in any of these roles. We are specifically interested in talking to you if you’re junior, really smart, and want to be given lots of responsibility to figure out the right way to do your job.</p>

<p>(And as always, even if you aren’t interested in any of this, if you’re a software engineer and you need a new job, you should use us! Talk to me about this too.)</p>

  </div>

  <hr />

  <h2><a href="/2016/06/22/ctci.html"> Studying for startup interviews with 'Cracking the Coding Interview'</a></h2>

  <p class="post-meta"><time datetime="2016-06-22T00:00:00-07:00" itemprop="datePublished">Jun 22, 2016</time></p>

  <div class="shrink-headings">
    <p><a href="https://www.amazon.com/Cracking-Coding-Interview-Programming-Questions/dp/098478280X">Cracking the Coding Interview</a> is by far the most popular interview prep book for software engineers. It’s a great book. But it was written for a few years ago, and software engineering interviews seem to have changed in the meantime, at least in the Silicon Valley engineering culture which I’m most involved in.</p>

<p>So I’ve written this guide to the book. It contains notes on things which I think have changed since it was written, and a list of the questions from the book which I think are most relevant to people preparing for software engineering interviews at good companies in the Bay Area.</p>

<p>I was inspired to write this by <a href="https://www.interviewcake.com/">InterviewCake</a>, which is a competitor to Cracking the Coding Interview. But InterviewCake is much more expensive than CtCI. I think this list of CtCI questions is about as good a list of interview questions as InterviewCake. There, I just saved you $180.</p>

<p>How have things changed? Most obviously, people use more scripting languages here and less C++ and Java. This has some direct effects. For example, there aren’t as many questions about merging arrays given buffer space anymore: that question still makes sense in scripting languages, but it doesn’t come up as much as it does in C. And I think Silicon Valley dislikes what it sees as verbose enterprise trivia bullshit, and purposefully doesn’t talk about such things. I think this is why I don’t hear about people being asked about design patterns.</p>

<p>The 5th edition is somewhat better than the 4th edition, because it has more content at the start of every chapter. I have not seen the 6th edition.</p>

<h2 id="the-most-relevant-questions">The most relevant questions</h2>

<p>Here is a subset of the questions which I think reflects SF software interviews more accurately:</p>

<p>Questions in the 4th edition:</p>

<p>1.1, 1.7, 1.8, 2.1, 3.1, 3.2, 3.3, 3.5, 4.1, 4.2, 4.3, 4.5, 4.8, 7.1, 7.2, 7.4, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 9.2, 9.3, 9.6, 12.1, 12.2, 12.6, 12.7, 15.3, 17.5, 18.1, 18.2, 19.2, 19.7, 19.11, 20.10, 20.11.</p>

<p>Questions in the 5th edition:</p>

<p>1.1, 1.7, 1.8, 2.1, 3.1, 3.2, 3.3, 3.5, 3.7, 4.1, 4.2, 4.3, 4.5, 4.6, 4.8, 5.1, 8.1, 8.2, 8.5, 8.7, 8.9, 8.10, 9.1, 9.2, 9.3, 9.4, 9.5, 10.1, 10.2, 10.5, 10.6, 11.3, 11.6, 11.8, 15.5, 16.1, 17.2, 17.8, 17.12, 18.10, 18.11.</p>

<p>(Making those two lists felt like maintaining a codebase to work in both Python 2 and 3)</p>

<p>I would recommend giving these questions higher priority in your study.</p>

<p>Many of the questions that I didn’t include there are still good practice. If you want more practise on a particular topic, you should definitely do even the questions I didn’t include.</p>

<h2 id="general-notes">General notes</h2>

<p>Every chapter in the interview questions section of CtCI starts with a short summary of the subject matter for the questions. I think these notes are quite good. It’s well worth reading the notes for chapters even if you don’t do questions from them.</p>

<p>The first 40-ish pages of the book are general advice about software engineering interviews. I agree with all of it except the following points, organized by section:</p>

<p><strong>Before the interview</strong>: Companies don’t ask behavioral questions much.</p>

<p><strong>What You Need To Know (page 26)</strong>: Tries are not absolutely must-have knowledge. I’ve never heard of people being asked to implement quicksort in place. Singleton and Factory design patterns are not crucial knowledge.</p>

<p><strong>At the Interview</strong>: You don’t have to use C, C++, or Java. People will possibly be biased against you if you do. Ruby, Python, and Javascript are fine choices. I think it’s fine to do the problem in whatever language you want. You can ask your recruiter about this before the interview.</p>

<h2 id="comments-on-individual-question-chapters-in-the-4th-edition">Comments on individual question chapters (in the 4th edition):</h2>

<h3 id="chapter-1-arrays-and-strings">Chapter 1: Arrays and Strings</h3>

<p>Companies care less about seeing you edit data in place than they used to. I’d only expect questions on this if you’re applying for a C job. For this reason, questions [1.2, 1.3, 1.5, 1.6, 1.7] are lower priority.</p>

<h3 id="chapter-2-linked-lists">Chapter 2: Linked Lists</h3>

<p>All of these questions are less common these days because linked lists come up less, because we don’t use C as much and have more support for generics, leading to us coding our own data structures less often.</p>

<p><a href="http://bshlgrs.github.io/2016/04/22/dumbest-algorithm-problem.html">Fuck question 2.2.</a></p>

<p>2.5 is a common bullshit brainteaser question.</p>

<h3 id="chapter-3-queues-and-stacks">Chapter 3: Queues and stacks</h3>

<p>I agree that you’ll look good if you can flawlessly implement a queue and stack.</p>

<h3 id="chapter-4-graphs-and-trees">Chapter 4: Graphs and trees</h3>

<p>Study BFS: it’s a really common question. These questions all seem reasonable.</p>

<h3 id="chapter-5-bit-manipulation">Chapter 5: Bit manipulation</h3>

<p>I’ve rarely seen these problems come up, even when I interviewed for a C++ systems job.</p>

<p>I include one question of this type in my list above.</p>

<h3 id="chapter-6-brainteasers">Chapter 6: Brainteasers</h3>

<p>These questions are widely reviled, and seem to be getting less common. Maybe memorize the answers in case you run across a bad interviewer.</p>

<h3 id="chapter-7-oop">Chapter 7: OOP</h3>

<p>These questions are good. The provided answers are idiomatic Java; if you’re answering in Python you should model your answers after idiomatic Python rather than the answers given.</p>

<p>I don’t hear about people being asked abstract questions like 7.3.</p>

<h3 id="chapter-8-recursion">Chapter 8: Recursion</h3>

<p>Many of these questions are classics which I’ve been asked many times before.</p>

<h3 id="chapter-9-searching-and-sorting">Chapter 9: Searching and sorting</h3>

<p>I think that it’s somewhat less common to be asked to write sorting algorithms these days.</p>

<h3 id="chapter-10-math">Chapter 10: Math</h3>

<p>I don’t hear about math questions being asked, except at extremely math heavy companies to applicants with a hardcore math background.</p>

<h3 id="chapter-11-testing">Chapter 11: Testing</h3>

<p>I don’t hear about these questions very much. I’ve never heard questions like “how would you test a pen”.</p>

<h3 id="chapter-12-system-design-and-memory-limits">Chapter 12: System design and memory limits</h3>

<p>I don’t hear about memory limit questions very often.</p>

<h3 id="chapter-13-and-14-c-and-java">Chapter 13 and 14: C++ and Java</h3>

<p>Only relevant if you’re interviewing in C++ or Java, and even then I’d be slightly surprised to get these questions–they seem somewhat like trivia to me. That said, I’ve been asked one of these questions before.</p>

<h3 id="chapter-15-databases">Chapter 15: Databases</h3>

<p>The advice given is somewhat out of date. I don’t think that I’ve ever heard about someone being asked to denormalize their SQL database schema for speed in an interview.</p>

<p>I think the “design a database to hold certain data” type questions are more common now. The rise of ORMs has led to SQL being somewhat less important for most developers.</p>

<h3 id="chapter-16-low-level">Chapter 16: Low level</h3>

<p>These questions are great, but I wouldn’t expect them at most generalist job interviews.</p>

<h3 id="chapter-17-networking">Chapter 17: Networking</h3>

<p>This is somewhat more low level than I think most people get asked. It’s worth knowing the answer to the famous “what happens after you type a URL into a browser” question though.</p>

<h3 id="chapter-18-threads-and-locks">Chapter 18: Threads and Locks</h3>

<p>Companies don’t seem to ask about concurrency primitives without warning you beforehand. Some of these questions are Java-specific.</p>

<h3 id="chapter-19-and-20-moderate-and-hard">Chapter 19 and 20: Moderate and Hard</h3>

<p>All these questions are popular questions. I don’t particularly like them.</p>

  </div>

  <hr />

  <h2><a href="/2016/06/16/kth-richest.html"> 'Who is the kth richest person with age between x and y'</a></h2>

  <p class="post-meta"><time datetime="2016-06-16T00:00:00-07:00" itemprop="datePublished">Jun 16, 2016</time></p>

  <div class="shrink-headings">
    <p>Suppose I want to maintain a set of people where each has an age and a wealth. I want to be able to quickly insert people, delete people, and answer queries of the form “find the $latex k$th richest person whose age is between $latex x$ and $latex y$”.</p>

<p>Here is a summary of solutions to different variants on this question:</p>

<table class="table" id="table1">
  <tr>
    <th>Variation</th>
    <th>Solution details</th>
    <th>Space</th>
    <th>Update time</th>
    <th>Query time</th>
  </tr>
  <tr>
    <td>No insertion or deletion, one-sided interval</td>
    <td><a href="http://stackoverflow.com/a/31162190/1360429">Persistent binary search trees</a></td>
    <td>$latex n \cdot \log(n)$</td>
    <td>N/A</td>
    <td>$latex \log(n)$</td>
  </tr>
  <tr>
    <td>No insertion or deletion, two-sided interval</td>
    <td><a href="http://stackoverflow.com/questions/26296624/order-statistic-on-intervals/26299986#26299986">Persistent binary search trees</a></td>
    <td>$latex n \cdot \log(n)$</td>
    <td>N/A</td>
    <td>$latex \log(n)$</td>
  </tr>
  <tr>
    <td>Insertion, deletion, two-sided interval</td>
    <td>My answer, presented here</td>
    <td>$latex n \cdot \log(n)$</td>
    <td>$latex \log^2(n)$</td>
    <td>$latex \log^3(n)$</td>
  </tr>
</table>

<p>I have been somewhat interested in this question for about a year, and I’ve asked about related questions <a href="https://www.facebook.com/bshlgrs/posts/10205556609689335">a few</a> <a href="http://stackoverflow.com/questions/31153033/data-structure-to-support-a-particular-query-on-a-set-of-2d-points">times</a>. But no-one’s ever managed to give me a complete answer.</p>

<p>The other day, I ran across <a href="http://stackoverflow.com/a/26299986/1360429">this StackOverflow answer</a>, which presents an answer which I modified to make a full solution, which I’ll present here.</p>

<p>My solution allows insertion and deletion in $latex O(\log^2(n))$, and allows the query in $latex O(\log^3(n))$.</p>

<h2 id="solution">Solution</h2>

<p>Store an <a href="https://en.wikipedia.org/wiki/Order_statistic_tree">order statistic tree</a> ordered on age. At every node, store a pointer to an auxiliary order statistic tree, of all of that node’s descendants ordered on income.</p>

<p>At every node, this requires an extra amount of memory which is linear in the number of descendants of that node. So this means that the tree will take $latex O(n\cdot \log(n))$ memory overall.</p>

<h3 id="query">Query</h3>

<p>You might want to go read <a href="http://stackoverflow.com/a/26299986/1360429">that second StackOverflow answer</a> again, because this algorithm is similar to that one, and it’s easier to understand the algorithm on arrays.</p>

<p>The query is similar to how queries across ranges of an augmented BST usually work: we start out by finding the set of nodes whose descendants contain the whole subsection of the tree that you care about. There will be $latex \log(n)$ of these nodes, and finding all of them takes $latex \log(n)$ time.</p>

<p>We end up with $latex \log(n)$ OSTs of maximum size $latex O(n)$, and we want to find the $latex k$th smallest item in their disjoint union.</p>

<p>As discussed <a href="/2016/06/16/generalized-multi-quickselect.html">here</a>, we can solve that query in $latex O\left(\log(n)^3\right)$.</p>

<p>Alternatively, if your $latex k$ is small, you can directly traverse the trees to find the correct answer, which takes $latex k \log(n) + n$ time.</p>

<h3 id="updates">Updates</h3>

<p>When I insert a new value into my set, I need to update the auxiliary OSTs of all of the ancestor nodes of my new node.</p>

<p>Usually, it’s easy to argue that maintaining auxiliary data in your OST is fast, because usually your auxiliary data is something like “the sum of your descendants” or something which is $latex O(1)$. In this data structure, the efficiency argument is somewhat more complicated.</p>

<p>Inserting a single item into an OST takes $latex O(\log(n))$ time. But making the OST from scratch takes $latex O(n)$. This is concerning because it means that tree rotations are potentially extremely expensive. If I had to do tree rotations all the way up from my new node to the root of the tree every single insertion, then insertion would take linear time.</p>

<p>Luckily, we can decide that our OST is balanced using the red-black tree rules. Insertion in a red-black tree only involves amortized $latex O(1)$ rotations. (See <a href="web.stanford.edu/class/cs166/lectures/05/Small05.pdf">here</a> for an explanation of this.)</p>

<p>The node at the lowest level will have to totally regenerate its auxiliary OST every insertion, of course. Its parent will have to do a tree rotation which requires it to totally regenerate its auxiliary OST every second insertion. Its grandparent will need to do that $latex \frac14$ of the time. And then $latex \frac18$ and so on.</p>

<p>At height $latex h$ in the tree, defining the leaves to be $latex h=0$, the amortized cost of insertion is going to be $latex O(\log(2^h)) = O(h)$ for insertion plus $latex O\left(\frac{2^h}{2^h}\right) = O(1)$ for totally recreating the OST after a rebalance, for a total cost of $latex O(h)$.</p>

<p>The total time required for updating all the auxiliary OSTs after an insert is therefore:</p>

<script type="math/tex; mode=display">O\left(\sum_{h=0}^{log(n)} h \right)= O\left(\log(n)^2\right)</script>

<p>Updating or deleting a node also takes $latex O\left(\log(n)^2\right)$, for the same reason.</p>

<h2 id="variations">Variations</h2>

<h3 id="limited-latex-k">limited $latex k$</h3>

<p>If $latex k$ is always going to fixed below a particular limit $latex l$–say, you know ahead of time that you’re never going to need to know farther back than the 50th richest person between two ages–each node in your main OST can store a smaller auxiliary tree with only $latex l$ elements in it.</p>

<p>This reduces memory requirements to $latex O(n \cdot l)$.</p>

<p><strong>Queries</strong>: Using the algorithm for OSTs in <a href="/2016/06/16/generalized-multi-quickselect.html#table1">this table</a>, the cost is now $latex \log(\log(n) \cdot l) \cdot \log(n) \cdot \log(l)$, which looks like $latex \log(\log(n)) \cdot \log(n) \cdot \log(l)$ as $latex n$ grows.</p>

<p><strong>Updates</strong>: Every ancestor needs to do $latex \log(l)$ work now, instead of $latex \log(n)$, but you still have $latex \log(n)$ ancestors. So update takes overall $latex \log(n)\log(l)$ time.</p>

  </div>

  <hr />

  <h2><a href="/2016/06/16/generalized-multi-quickselect.html"> Generalized multi-quickselect</a></h2>

  <p class="post-meta"><time datetime="2016-06-16T00:00:00-07:00" itemprop="datePublished">Jun 16, 2016</time></p>

  <div class="shrink-headings">
    <p>I’ve been thinking a lot recently about how you find the $latex k$th smallest element in the disjoint union of several data structures.</p>

<h2 id="multi-quickselect-on-data-structures-with-fast-rank">Multi-quickselect on data structures with fast <code class="highlighter-rouge">rank</code></h2>

<p>Yesterday I <a href="/2016/06/15/multi-sorted-array-quickselect">came up with an algorithm similar to quickselect</a> for the version of this problem where you have multiple sorted arrays.</p>

<p>But this algorithm also works on any other data structure which supports the <code class="highlighter-rouge">rank</code> method in $latex O(\log(n))$ time.</p>

<p>On a collection of data structures with a total of $latex O(t)$ elements, the modified quickselect algorithm involves $latex O(log(t))$ iterations. In each iteration, the rank of a random element is computed in every data structure.</p>

<p>So the total time taken is (time to calculate rank in every data structure) * (log of total number of elements).</p>

<table class="table" id="table1">
  <tr>
    <th>Collection</th>
    <th>Time complexity</th>
  </tr>
  <tr>
    <td>$latex m$ sorted arrays of average length $latex n$</td>
    <td>$latex \log(m \cdot n) \cdot m \cdot \log(n)$</td>
  </tr>
    <tr>
    <td>$latex m$ sorted arrays of total length $latex t$</td>
    <td>$latex \log(t) \cdot m \cdot \log(\frac tm)$</td>
  </tr>
  <tr>
    <td>Two sorted arrays, of lengths $latex a$ and $latex b$</td>
    <td>$latex \log(a + b)^2$</td>
  </tr>
  <tr>
    <td>$latex m$ order statistic trees of average size $latex n$</td>
    <td>$latex \log(m \cdot n) \cdot m \cdot \log(n)$</td>
  </tr>
  <tr>
    <td>$latex \log(n)$ sorted arrays of sizes $latex [1, 2, 4, ...n]$</td>
    <td>$latex \log(n)^3$ </td>
  </tr>
</table>

<p>(See <sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup> for more details on the exponentially shrinking arrays.)</p>

<p>For data structures with $latex O(log(n))$ <code class="highlighter-rouge">rank</code>, I think this is optimal.</p>

<h2 id="allowing-data-structures-without-fast-rank">Allowing data structures without fast <code class="highlighter-rouge">rank</code></h2>

<p>How about if some of your data structures are unsorted?</p>

<p>This algorithm needs to be modified, because there’s no particular guarantee that any data structure gets smaller on a particular iteration. This is okay in cases where <code class="highlighter-rouge">rank</code> is cheap enough that the asymptotic complexity isn’t affected by having a data structure which stays at its original size for most of the runtime of the algorithm. But on an unsorted array, <code class="highlighter-rouge">rank</code> takes $latex O(n)$ and a key part of the argument for the good runtime of quickselect is that the unordered array usually gets smaller every time you call <code class="highlighter-rouge">rank</code>.</p>

<p>This issue is why my attempt at an <a href="/2016/06/12/quickselect-lemma.html">optimal algorithm for selection on an OST and an unsorted array</a> was so complex.</p>

<p>Obviously there’s not going to be a sublinear time solution to this problem. So we might as well take linear time to add all our unsorted structures together into an unsorted array, in linear time. So we only need to consider the problem where we have a single unsorted array.</p>

<h3 id="non-optimal-solution">Non-optimal solution</h3>

<p>When I have a collection of data structures such that <code class="highlighter-rouge">rank</code> takes time $latex O(r)$ and <code class="highlighter-rouge">select</code> takes time $latex O(s)$, I can run <a href="/2016/06/12/quickselect-lemma.html">my <code class="highlighter-rouge">double_quickselect_v2</code> algorithm</a> on an unordered array of length $latex n$ and that collection, with query time $latex O(\log(n) \cdot r + s)$. For example, this algorithm can deal with a sorted array of size $latex m$ and an unsorted array of size $latex n$ in overall $latex O(\log(n) \cdot \log(m) + \log(m)) = O(\log(m)\cdot\log(n))$.</p>

<h3 id="what-an-optimal-solution-might-look-like">What an optimal solution might look like</h3>

<p>I bet we can generalize my alleged <a href="/2016/06/12/quickselect-lemma.html">optimal algorithm for selection on an OST and an unsorted array</a>.</p>

<h2 id="summary">Summary</h2>

<p>I have a bunch of data structures and want to find the $latex k$th smallest item in their union. How long will it take me?</p>

<table class="table" id="table1">
  <tr>
    <th>Collection</th>
    <th>Algorithm</th>
    <th>Time complexity</th>
  </tr>
  <tr>
    <td>Unsorted array of size $latex n$</td>
    <td>Median of medians</td>
    <td>Worst case $latex O(n)$</td>
  </tr>
  <tr>
    <td>Sorted array of size $latex n$</td>
    <td>Binary search</td>
    <td>Worst case $latex O(\log(n))$</td>
  </tr>
  <tr>
    <td>Order statistic tree</td>
    <td>its native `find` implementation</td>
    <td>Worst case $latex O(\log(n))$</td>
  </tr>
  <tr>
    <td>A bunch of unsorted data structures, of total size $latex O(n)$</td>
    <td>Stick it all in an array then call median of medians</td>
    <td>Worst case $latex O(\log(n))$</td>
  </tr>
  <tr>
    <td>$latex m$ data structures which support <code>rank</code> in $latex O(\log(n))$, with maximum size $latex O(n)$</td>
    <td><a href="/2016/06/15/multi-sorted-array-quickselect.html">Multi sorted array quickselect</a></td>
    <td>Average case $latex O(m \cdot \log(n) \cdot \log(m \cdot n))$</td>
  </tr>
  <tr>
    <td>$latex m$ data structures which support <code>rank</code> in $latex O(\log(n))$, with maximum size $latex O(n)$, and also a bunch of unsorted data with total size $latex u$</td>
    <td>"Non-optimal solution" as described above</td>
    <td>Average case $latex O(\log(u) \cdot m \cdot \log(n) +\\ m \cdot \log(n) \cdot \log(m \cdot n))$</td>
  </tr>
</table>

<p>I suspect that I can improve upon most of the algorithms listed there that I invented myself; I’ll keep this table updated.</p>

<p>If you know a faster algorithm for one of these problems, please let me know!</p>

<div class="footnotes">
  <ol>
    <li id="fn:1">

      <p>There are a total of $latex 2\cdot n - 1 = O(n)$ elements in those $latex n$ arrays. The inner loop will happen $latex \log(n)$ times.</p>

      <p>Each iteration will need to do a binary search within its array. On the first iteration the time taken will be $latex \sum_{i=0}^{\log(n)} \log(2^i) = O(\log(n)^2)$. Further iterations obviously won’t be slower than that. So we can bound above this runtime by $latex \log(n)$.</p>

      <p>We can also give a proof sketch for bounding it below. Suppose that all our arrays have roughly the same distribution, so that on the $latex w$th iteration, every array has a size of only $latex 2^{-w}$ its original size.</p>

      <script type="math/tex; mode=display">% <![CDATA[
\begin{align} &\sum_{w=0}^{\log(n)} \sum_{i=0}^{\log(n)} \log\left(max\left(2^i \cdot 2^{-w}, 0\right)\right)  \\
        = &\sum_{w=0}^{\log(n)} \sum_{i=0}^{w} i  \\
        = &\sum_{w=0}^{\log(n)} O\left( w^2 \right) \\
        = &O\left(\log(n)^3\right) \end{align} %]]></script>
      <p><a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>

  </div>

  <hr />

  <h2><a href="/2016/06/15/multi-sorted-array-quickselect.html"> Quickselect on multiple sorted arrays</a></h2>

  <p class="post-meta"><time datetime="2016-06-15T00:00:00-07:00" itemprop="datePublished">Jun 15, 2016</time></p>

  <div class="shrink-headings">
    <p><strong>Edit: Thanks heaps to <a href="http://stackoverflow.com/users/1009831/evgeny-kluev">Evgeny Kluev</a>, the author of that original StackOverflow answer, for noticing that I’d made a mistake in the total time complexity calculation.</strong></p>

<p><strong>Edit 2016-06-18: I’d orignally described this with arrays of maximum length $latex n$. But it works just as well with arrays of average length $latex n$, which is a stronger statement, so I’d rather use this one.</strong></p>

<p>Suppose I have $latex m$ sorted arrays of average length $latex n$. How quickly can I search to find the $latex k$th item in them?</p>

<p><a href="http://stackoverflow.com/a/26299986/1360429">This StackOverflow answer</a> mentions this problem offhandedly, but doesn’t clearly explain the algorithm, and it implies that the answer it’s thinking of is $latex O(m^2 \log(n)^2)$.</p>

<p>We can do better. You can modify quickselect to get an algorithm which takes $latex O(m \log(n) \log(m \cdot n))$ average case, and I suspect you can adapt <a href="https://en.wikipedia.org/wiki/Median_of_medians">median of medians</a> to get that time in the worst case.</p>

<p>The quickselect adaptation is pretty simple. We’re going to be do a simultaneous binary search on every array. For simplicity, let’s assume that all items in arrays are unique.</p>

<p>We’re going to need a <code class="highlighter-rouge">rank</code> method, which does a binary search to determine the number of items in an array smaller than its argument <code class="highlighter-rouge">x</code>. Here is such a method:</p>

<div class="language-ruby highlighter-rouge"><pre class="highlight"><code><span class="c1"># Returns the number of items in arr smaller than x.</span>
<span class="k">def</span> <span class="nf">rank</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">start_idx</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">end_idx</span> <span class="o">=</span> <span class="kp">nil</span><span class="p">)</span>
  <span class="k">return</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">arr</span><span class="p">.</span><span class="nf">empty?</span>

  <span class="n">end_idx</span> <span class="o">=</span> <span class="n">arr</span><span class="p">.</span><span class="nf">length</span> <span class="k">if</span> <span class="n">end_idx</span><span class="p">.</span><span class="nf">nil?</span>

  <span class="c1"># this makes sense I promise, I'll explain later</span>
  <span class="k">return</span> <span class="n">arr</span><span class="p">.</span><span class="nf">length</span> <span class="k">if</span> <span class="n">start_idx</span> <span class="o">==</span> <span class="n">arr</span><span class="p">.</span><span class="nf">length</span>
  <span class="k">return</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">end_idx</span> <span class="o">==</span> <span class="mi">0</span>

  <span class="kp">loop</span> <span class="k">do</span>
    <span class="n">mid_idx</span> <span class="o">=</span> <span class="p">((</span><span class="n">start_idx</span> <span class="o">+</span> <span class="n">end_idx</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">).</span><span class="nf">floor</span>

    <span class="k">if</span> <span class="n">arr</span><span class="p">[</span><span class="n">mid_idx</span><span class="p">]</span> <span class="o">==</span> <span class="n">x</span>
      <span class="k">return</span> <span class="n">mid_idx</span>
    <span class="k">elsif</span> <span class="n">arr</span><span class="p">[</span><span class="n">mid_idx</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">x</span>
      <span class="k">return</span> <span class="n">start_idx</span> <span class="k">if</span> <span class="n">end_idx</span> <span class="o">-</span> <span class="n">start_idx</span> <span class="o">&lt;=</span> <span class="mi">1</span>
      <span class="n">end_idx</span> <span class="o">=</span> <span class="n">mid_idx</span>
    <span class="k">else</span>
      <span class="k">return</span> <span class="n">end_idx</span> <span class="k">if</span> <span class="n">end_idx</span> <span class="o">-</span> <span class="n">start_idx</span> <span class="o">&lt;=</span> <span class="mi">1</span>
      <span class="n">start_idx</span> <span class="o">=</span> <span class="n">mid_idx</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre>
</div>

<p>Now here’s how the select method is going to work. We’re going to start by setting up a <code class="highlighter-rouge">limits</code> variable. Normally in binary search, you need to store two variables, <code class="highlighter-rouge">start_idx</code> and <code class="highlighter-rouge">end_idx</code>. In our case, we’re going to store these two variables for every array we’re working with.</p>

<p>Every iteration, we’re going to randomly choose a pivot from the elements that haven’t been ruled out yet. Then we’re going to binary search all of the arrays to find the rank of the pivot in each of the arrays. We can add all these ranks together to find the rank of the pivot overall.</p>

<p>If the rank of the pivot is equal to <code class="highlighter-rouge">k</code>, then we return our pivot and stop recursing.</p>

<p>If the rank of the pivot is greater than <code class="highlighter-rouge">k</code>, our pivot is larger than the true result. So we can rule out every value which is larger than our pivot. For every array, we set its <code class="highlighter-rouge">end_idx</code> to the rank which it computed for the pivot.</p>

<p>If the rank of the pivot is smaller than k, then do the opposite: set the <code class="highlighter-rouge">start_idx</code> array to the rank array.</p>

<p>Here’s an implementation of that:</p>

<div class="language-ruby highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">quickselect_in_sorted_arrays</span><span class="p">(</span><span class="n">arrays</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">arrays</span><span class="p">.</span><span class="nf">first</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">if</span> <span class="n">arrays</span><span class="p">.</span><span class="nf">length</span> <span class="o">==</span> <span class="mi">1</span>

  <span class="n">arrays</span><span class="p">.</span><span class="nf">select!</span> <span class="p">{</span> <span class="o">|</span><span class="n">x</span><span class="o">|</span> <span class="n">x</span><span class="p">.</span><span class="nf">length</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="p">}</span>

  <span class="k">return</span> <span class="kp">nil</span> <span class="k">if</span> <span class="n">k</span> <span class="o">&gt;=</span> <span class="n">arrays</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="o">&amp;</span><span class="ss">:count</span><span class="p">).</span><span class="nf">reduce</span><span class="p">(</span><span class="o">&amp;</span><span class="p">:</span><span class="o">+</span><span class="p">)</span>

  <span class="c1"># In a single binary search, we have variables `start_idx`</span>
  <span class="c1"># and `end_idx`.</span>

  <span class="c1"># In this binary search, we need those variables for</span>
  <span class="c1"># every array. So we'll keep them in these arrays.</span>
  <span class="n">start_indexes</span> <span class="o">=</span> <span class="n">arrays</span><span class="p">.</span><span class="nf">map</span> <span class="p">{</span> <span class="mi">0</span> <span class="p">}</span>
  <span class="n">end_indexes</span> <span class="o">=</span> <span class="n">arrays</span><span class="p">.</span><span class="nf">map</span> <span class="p">{</span> <span class="o">|</span><span class="n">arr</span><span class="o">|</span> <span class="n">arr</span><span class="p">.</span><span class="nf">length</span> <span class="p">}</span>

  <span class="kp">loop</span> <span class="k">do</span>
    <span class="c1"># Randomly select an item from the viable candidates.</span>
    <span class="c1"># (This is obviously not an efficient implementation)</span>
    <span class="n">pivot</span> <span class="o">=</span> <span class="n">arrays</span><span class="p">.</span><span class="nf">map</span>
                  <span class="p">.</span><span class="nf">with_index</span> <span class="k">do</span> <span class="o">|</span><span class="n">arr</span><span class="p">,</span> <span class="n">idx</span><span class="o">|</span>
                    <span class="n">arr</span><span class="p">[</span><span class="n">start_indexes</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">end_indexes</span><span class="p">[</span><span class="n">idx</span><span class="p">]]</span>
                  <span class="k">end</span>
                  <span class="p">.</span><span class="nf">flatten</span>
                  <span class="p">.</span><span class="nf">sample</span>


    <span class="c1"># Find the rank of the pivot in every array.</span>
    <span class="n">pivot_ranks</span> <span class="o">=</span> <span class="n">arrays</span><span class="p">.</span><span class="nf">map</span><span class="p">.</span><span class="nf">with_index</span> <span class="k">do</span> <span class="o">|</span><span class="n">arr</span><span class="p">,</span> <span class="n">idx</span><span class="o">|</span>
      <span class="n">rank</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">pivot</span><span class="p">,</span> <span class="n">start_indexes</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">end_indexes</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
    <span class="k">end</span>

    <span class="c1"># What is `pivot`'s overall rank in these arrays?</span>
    <span class="n">overall_rank_of_pivot</span> <span class="o">=</span> <span class="n">pivot_ranks</span><span class="p">.</span><span class="nf">reduce</span><span class="p">(</span><span class="o">&amp;</span><span class="p">:</span><span class="o">+</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">overall_rank_of_pivot</span> <span class="o">==</span> <span class="n">k</span>
      <span class="c1"># we're done! woohoo!</span>
      <span class="k">return</span> <span class="n">pivot</span>
    <span class="k">elsif</span> <span class="n">overall_rank_of_pivot</span> <span class="o">&gt;</span> <span class="n">k</span>
      <span class="c1"># our pivot was apparently too big.</span>

      <span class="c1"># On the plus side, we now know that wherever our binary</span>
      <span class="c1"># searches just finished, everything to the right of that</span>
      <span class="c1"># in that array is now guaranteed not to be the result.</span>
      <span class="n">pivot_ranks</span><span class="p">.</span><span class="nf">each_with_index</span> <span class="k">do</span> <span class="o">|</span><span class="n">rank</span><span class="p">,</span> <span class="n">idx</span><span class="o">|</span>
        <span class="n">end_indexes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">rank</span>
      <span class="k">end</span>
    <span class="k">else</span>
      <span class="c1"># If our pivot was too small, then we can rule out</span>
      <span class="c1"># everything to the left of those ranks.</span>
      <span class="n">pivot_ranks</span><span class="p">.</span><span class="nf">each_with_index</span> <span class="k">do</span> <span class="o">|</span><span class="n">rank</span><span class="p">,</span> <span class="n">idx</span><span class="o">|</span>
        <span class="n">start_indexes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">rank</span>
      <span class="k">end</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre>
</div>

<p>For full source code including some random testcases, <a href="https://gist.github.com/bshlgrs/14801efbb27d447fa7a2afba97ab70b4">look here</a>.</p>

<p>How fast is this method? The main loop costs $latex m \log(n)$ per iteration. How many times will we run it? Well, every time we run the iteration, we cut out all the elements which are on the wrong side of the result from our pivot. Worst case, we keep choosing the worst possible pivot and only ruling it out, which means we need to run that iteration once for every item in all of the arrays. This is $latex O(m^2 n \log(n))$.</p>

<p>But on average, we’ll cut a constant fraction of our search space out every time. So we should expect to have to do that iteration $latex \log(m\cdot n) = \log(m) + \log(n)$ times, for an overall time complexity of $latex O(m \log(n) \log(m \cdot n))$.</p>

<p>(Incidentally, when I was initially thinking about this, I thought we might get some speedup because our call to <code class="highlighter-rouge">rank</code> is going to be on a smaller and smaller section of its array every iteration throuhgh the loop. But I don’t think that’s true, because to get an asympotic decrease in the sum of a bunch of logarithms, you need to make your problem sizes decrease extremely quickly; exponentially decaying problem size doesn’t cut it. For example:</p>

<script type="math/tex; mode=display">O\left(\sum_{i=0}^n \log\left(2^i\right) \right) = O(\log(n)^2) = O\left(\sum_{i=0}^n \log\left(2^n\right) \right)</script>

<p>because</p>

<script type="math/tex; mode=display">O\left(\sum_{i=0}^n i \right) = O(n^2) = O\left(\sum_{i=0}^n n \right)</script>

<p>So I don’t think we can make that work.)</p>

<h2 id="further-questions">Further questions</h2>

<ul>
  <li>Can we generalize the <a href="https://en.wikipedia.org/wiki/Median_of_medians">median of medians</a> algorithm to get this to be guaranteed fast, rather than expected fast? The answer is almost certainly yes; I’ll probably try to prove it sometime.</li>
</ul>

  </div>

  <hr />

  <h2><a href="/2016/06/12/quickselect-lemma.html"> Quickselect on an unordered array and an order statistic tree</a></h2>

  <p class="post-meta"><time datetime="2016-06-12T00:00:00-07:00" itemprop="datePublished">Jun 12, 2016</time></p>

  <div class="shrink-headings">
    <p><strong>I did this work myself, so there are probably mistakes. I think the conclusion is right though.</strong></p>

<p>Suppose I have an <a href="https://en.wikipedia.org/wiki/Order_statistic_tree">order statistic tree</a> with $latex n$ elements and an unordered list with $latex m$ elements. Let’s say for the sake of simplicity that both are representing a set of items with no duplicates, and their intersection is empty.</p>

<p>If you want to find the $latex k$th element of the order statistic tree, you can do that in $latex O(log(n))$ time. And if you want to find the $latex k$th element of the array, you can use <a href="https://en.wikipedia.org/wiki/Quickselect">quickselect</a> and get it in $latex O(m)$ time. I want to find the $latex k$th smallest item in the disjoint union of these lists. How quickly can I do this?</p>

<p>You can do it trivially in $latex O(m + n)$ time, by flattening the order statistic tree (which I’ll call an OST from here onwards) onto the end of the array. Or you can add everything in the array to the OST and then query the OST, in $latex O(m \cdot \log(n + m))$ time.</p>

<p>I have found solutions that run in $latex O(m \cdot \log(n))$, $latex O(m + \log(m) \cdot \log(n))$, and $latex O(m + \log(n))$. The last of these is really complicated and annoying; the first two are pretty simple.</p>

<h2 id="order-statistic-trees">Order statistic trees</h2>

<p>I’m going to write code in Ruby, in which the <code class="highlighter-rouge">filter</code> method is stupidly named <code class="highlighter-rouge">select</code>. OSTs are usually presented with a method called <code class="highlighter-rouge">select(k)</code> which finds the $latex k$th smallest element. In this post I’m going to use the method name <code class="highlighter-rouge">find_kth_smallest</code> instead.</p>

<p>I’m going to assume that my OSTs have the following methods:</p>

<ul>
  <li><code class="highlighter-rouge">smallers</code>: returns the left subtree</li>
  <li><code class="highlighter-rouge">largers</code>: returns the right subtree</li>
  <li><code class="highlighter-rouge">pivot</code>: returns the value of the root node</li>
  <li><code class="highlighter-rouge">count</code>: returns the number of items in the node</li>
  <li><code class="highlighter-rouge">find_kth_smallest(k)</code>: as discussed above</li>
  <li><code class="highlighter-rouge">rank(x)</code>: finds the number of elements in the OST smaller than <code class="highlighter-rouge">x</code>. This takes $latex O(\log(n))$ in an OST.</li>
  <li><code class="highlighter-rouge">split_on_left_by_value(x)</code>: returns a new tree with only the items in the OST which are less than <code class="highlighter-rouge">x</code>. If our OSTs are immutable, this only takes $latex\log(n)$ time.</li>
  <li><code class="highlighter-rouge">split_on_right_by_value(x)</code>: like <code class="highlighter-rouge">split_on_left_by_value</code>, but the other side.</li>
</ul>

<h2 id="standard-quickselect">Standard quickselect</h2>

<p>Just for reference, here’s an unoptimized implementation of quickselect. This has average case performance $latex O(n)$.</p>

<div class="language-ruby highlighter-rouge"><pre class="highlight"><code><span class="c1"># assumes that the list has all unique elements</span>
<span class="c1"># returns the same thing as array.sort[n]</span>
<span class="k">def</span> <span class="nf">quickselect</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
  <span class="c1"># choose a random pivot</span>
  <span class="n">pivot_element</span> <span class="o">=</span> <span class="n">array</span><span class="p">.</span><span class="nf">sample</span>

  <span class="n">smallers</span> <span class="o">=</span> <span class="n">array</span><span class="p">.</span><span class="nf">select</span> <span class="p">{</span> <span class="o">|</span><span class="n">x</span><span class="o">|</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="n">pivot_element</span> <span class="p">}</span>
  <span class="n">largers</span> <span class="o">=</span> <span class="n">array</span><span class="p">.</span><span class="nf">select</span> <span class="p">{</span> <span class="o">|</span><span class="n">x</span><span class="o">|</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="n">pivot_element</span> <span class="p">}</span>

  <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="n">smallers</span><span class="p">.</span><span class="nf">length</span>
    <span class="n">quickselect</span><span class="p">(</span><span class="n">smallers</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
  <span class="k">elsif</span> <span class="n">n</span> <span class="o">==</span> <span class="n">smallers</span><span class="p">.</span><span class="nf">length</span>
    <span class="n">pivot_element</span>
  <span class="k">else</span>
    <span class="n">quickselect</span><span class="p">(</span><span class="n">largers</span><span class="p">,</span> <span class="n">n</span> <span class="o">-</span> <span class="n">smallers</span><span class="p">.</span><span class="nf">length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre>
</div>

<p>This has average case $latex O(n)$ performance because the recurrence relation is:</p>

<script type="math/tex; mode=display">f(n) = f\left(\frac{n}2\right) + n</script>

<h2 id="modified-quickselect-attempt-1-latex-om-cdot-logn">Modified quickselect, attempt 1: $latex O(m \cdot \log(n))$</h2>

<p>Let’s modify this to also use an OST.</p>

<div class="language-ruby highlighter-rouge"><pre class="highlight"><code><span class="c1"># OST has size n</span>
<span class="c1"># array has size m</span>
<span class="c1"># this returns the same thing as (array + ost.to_a).sort[k]</span>
<span class="k">def</span> <span class="nf">double_quickselect_v1</span><span class="p">(</span><span class="n">ost</span><span class="p">,</span> <span class="n">array</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
  <span class="n">smallers</span> <span class="o">=</span> <span class="n">arr</span><span class="p">.</span><span class="nf">select</span> <span class="p">{</span> <span class="o">|</span><span class="n">x</span><span class="o">|</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="n">ost</span><span class="p">.</span><span class="nf">pivot</span> <span class="p">}</span>
  <span class="n">largers</span> <span class="o">=</span> <span class="n">arr</span><span class="p">.</span><span class="nf">select</span> <span class="p">{</span> <span class="o">|</span><span class="n">x</span><span class="o">|</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="n">ost</span><span class="p">.</span><span class="nf">pivot</span> <span class="p">}</span>

  <span class="n">number_of_smaller_things</span> <span class="o">=</span> <span class="n">smallers</span><span class="p">.</span><span class="nf">length</span> <span class="o">+</span> <span class="n">ost</span><span class="p">.</span><span class="nf">smallers</span><span class="p">.</span><span class="nf">count</span>

  <span class="k">if</span> <span class="n">number_of_smaller_things</span> <span class="o">&gt;</span> <span class="n">k</span>
    <span class="n">double_quickselect_v1</span><span class="p">(</span><span class="n">smallers</span><span class="p">,</span> <span class="n">ost</span><span class="p">.</span><span class="nf">smallers</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
  <span class="k">elsif</span> <span class="n">number_of_smaller_things</span> <span class="o">==</span> <span class="n">k</span>
    <span class="n">ost</span><span class="p">.</span><span class="nf">pivot</span>
  <span class="k">else</span>
    <span class="n">double_quickselect_v1</span><span class="p">(</span><span class="n">largers</span><span class="p">,</span> <span class="n">ost</span><span class="p">.</span><span class="nf">largers</span><span class="p">,</span> <span class="n">k</span> <span class="o">-</span> <span class="n">number_of_smaller_things</span><span class="p">)</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre>
</div>

<p>Every time we make a recursive call, our order statistic tree halves in size. Our array might not get smaller though: eg if everything in your array is smaller than everything in your OST. Our OST has depth $latex \log(n)$, and in the worst case you need to iterate over everything in your array every time. So this is $latex O(m \cdot \log(n))$.</p>

<p>Can we do better? I think we can. Intuitively, it seems like this algorithm works to shrink the OST as fast as possible, and not really worry about the array. But the array is where most of the cost comes from. So we should try to organize this algorithm so that instead of halving the size of the OST every time, it halves the size of the array every time.</p>

<h2 id="modified-quickselect-attempt-2-latex-om--logm-cdot-logn">Modified quickselect, attempt 2: $latex O(m + \log(m) \cdot \log(n))$</h2>

<p>Instead of using the OST’s pivot, let’s pivot on a randomly selected member of the array, like in normal quickselect. This means that the array is probably going to shrink with every recursive call.</p>

<div class="language-ruby highlighter-rouge"><pre class="highlight"><code><span class="c1"># OST has size n</span>
<span class="c1"># array has size m</span>
<span class="c1"># this returns the same thing as (array + ost.to_a).sort[k]</span>
<span class="k">def</span> <span class="nf">double_quickselect_v2</span><span class="p">(</span><span class="n">ost</span><span class="p">,</span> <span class="n">array</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
  <span class="n">pivot_element</span> <span class="o">=</span> <span class="n">arr</span><span class="p">.</span><span class="nf">sample</span>
  <span class="n">smallers</span> <span class="o">=</span> <span class="n">arr</span><span class="p">.</span><span class="nf">select</span> <span class="p">{</span> <span class="o">|</span><span class="n">x</span><span class="o">|</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="n">pivot_element</span> <span class="p">}</span>
  <span class="n">largers</span> <span class="o">=</span> <span class="n">arr</span><span class="p">.</span><span class="nf">select</span> <span class="p">{</span> <span class="o">|</span><span class="n">x</span><span class="o">|</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="n">pivot_element</span> <span class="p">}</span>

  <span class="n">number_of_smaller_things</span> <span class="o">=</span> <span class="n">smallers</span><span class="p">.</span><span class="nf">length</span> <span class="o">+</span> <span class="n">ost</span><span class="p">.</span><span class="nf">rank</span><span class="p">(</span><span class="n">pivot_element</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">number_of_smaller_things</span> <span class="o">&gt;</span> <span class="n">k</span>
    <span class="n">double_quickselect_v2</span><span class="p">(</span><span class="n">smallers</span><span class="p">,</span>
                        <span class="n">ost</span><span class="p">.</span><span class="nf">split_on_right_by_value</span><span class="p">(</span><span class="n">pivot_element</span><span class="p">),</span>
                        <span class="n">k</span><span class="p">)</span>
  <span class="k">elsif</span> <span class="n">number_of_smaller_things</span> <span class="o">==</span> <span class="n">k</span>
    <span class="n">ost</span><span class="p">.</span><span class="nf">pivot</span>
  <span class="k">else</span>
    <span class="n">double_quickselect_v2</span><span class="p">(</span><span class="n">largers</span><span class="p">,</span>
                        <span class="n">ost</span><span class="p">.</span><span class="nf">split_on_left_by_value</span><span class="p">(</span><span class="n">pivot_element</span><span class="p">),</span>
                        <span class="n">k</span> <span class="o">-</span> <span class="n">number_of_smaller_things</span><span class="p">)</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre>
</div>

<p>So now the array is going to shrink on average by a factor of 2 every recursive call, but in the worst case the tree will stay the same size every time. So we now expect to $latex \log(m)$ recursive calls, for a total cost of $latex O(m + \log(m) \cdot \log(n))$.</p>

<p>(Incidentally, calling <code class="highlighter-rouge">ost.split_on_left_by_value</code> doesn’t affect the asymptotic runtime of this function, because this only decreases the size of <code class="highlighter-rouge">ost</code> by a constant multiplier in expectation, and it doesn’t cause <code class="highlighter-rouge">ost.rank(pivot_element)</code> to run asymptotically faster.)</p>

<p>Okay, this is better. But can we improve it even more?</p>

<h2 id="sketch-of-a-latex-om--logn-solution">Sketch of a $latex O(m + \log(n))$ solution</h2>

<p>I’m pretty sure I have an optimal solution, but it’s really complicated and annoying.</p>

<p>The problem was that in the previous algorithms, sometimes I computed expensive things for the data structures without any guarantee that they’d end up smaller. This time, I want to either compute tertiles for a data structure and shrink it, or ignore it.</p>

<p>For this to work, we’re going to need our OST to be a <a href="https://en.wikipedia.org/wiki/Weight-balanced_tree">weight-balanced tree</a>. Let’s set $latex \alpha = \frac 14$. (Actually, I think this algorithm works with non-weight-balanced trees, but I don’t know how to prove the time bound without the weight balance.)</p>

<p>Here’s how: At the start of every recursive call, we look at the relative sizes of the two data structures. If one is much larger than the other, we’re going to shrink the large one and ignore the small one. If they’re within a factor of 2 of each other, we’re going to call the expensive methods on both then shrink one of them.</p>

<p>If you want the gory details, read on.</p>

<h3 id="case-1-one-is-much-larger-than-the-other">Case 1: one is much larger than the other</h3>

<p>Suppose one data structure has more than three times as many things in it as the other one does. Let’s call the two data structures <code class="highlighter-rouge">Big</code> and <code class="highlighter-rouge">Small</code>. <code class="highlighter-rouge">Big</code> has size $latex b$, <code class="highlighter-rouge">Small</code> has size $latex s$.</p>

<p>Suppose we have 100 things in <code class="highlighter-rouge">Big</code> and 10 things in <code class="highlighter-rouge">Small</code>. We want to find the 15th largest thing in <code class="highlighter-rouge">Big ++ Small</code>. Let’s call the result $latex x$.</p>

<p>$latex x$ can’t be more than <code class="highlighter-rouge">Big.find_kth_smallest(15)</code>, because by definition there are 15 things in <code class="highlighter-rouge">Big</code> less than that.</p>

<p>And $latex x$ can’t be less than <code class="highlighter-rouge">Big.find_kth_smallest(5)</code>, because there are only 5 things in <code class="highlighter-rouge">Big</code> less than that, and there are only 10 things in Small.</p>

<p>So if we’re looking for the <code class="highlighter-rouge">k</code>th item in <code class="highlighter-rouge">Big ++ Small</code>, we can discard everything bigger than <code class="highlighter-rouge">Big.find_kth_smallest(k)</code>, and everything smaller than <code class="highlighter-rouge">Big.find_kth_smallest(k + s)</code>.</p>

<h4 id="case-1a-the-array-is-larger">Case 1a: the array is larger</h4>

<p>If the array is the larger data structure, then we do this discard by calling quickselect twice and copying everything between the two results to a new array. This takes $latex O(m)$ time, and the resulting array is at most size $latex s$. So we made our array half its original size.</p>

<h4 id="case-1b-the-ost-is-larger">Case 1b: the OST is larger</h4>

<p>If the tree is the larger data structure, then things are somewhat more annoying, because we only want to take constant time.</p>

<p>Selecting exactly the first $latex k$ things in an OST takes $latex \log(n)$ time. I’m going to suggest that instead of selecting exactly the first $latex k$ things, we should go a few layers deep in our OST and then delete only the nodes which we know we can safely delete.</p>

<p>Because we’re using weight-balanced trees with a weight balancing factor of $latex \frac 14$, we might need to go down maybe 3 layers in order to get a node with enough weight that deleting it deletes half the weight that you’d be able to delete if you called <code class="highlighter-rouge">split_on_left_by_value</code>. (I’m not sure about the number 3 being correct, but I think this is true for some constant.)</p>

<p>We could safely remove $latex \frac 12$ of the tree if we used the normal split methods. We’re going to remove more than half of that, so at worst our tree will end up $latex\frac 34$ of its original size.</p>

<p>So in both cases, we end up with the bigger data structure being a constant factor smaller.</p>

<h3 id="case-2-the-data-structures-are-a-similar-size">Case 2: the data structures are a similar size</h3>

<p>Oh man, this gets messy. I’m going to call this bit an “algorithm sketch”, because then you can’t criticise me for being handwavy.</p>

<p>Get approximate tertiles from the OST and exact tertiles from the array. This takes $latex O(m)$ time for the array and $latex O(1)$ time for the OST.</p>

<p>Then you compare these two inter-tertile ranges. There are three cases: they can intersect, they can be disjoint, or one can be inside the other. In each of these cases, based on your value of $latex k$ you can rule out at least a third of at least one of the two data structures. This is just a massive mess of cases. Here’s a diagram of one way it can play out when the ranges intersect:</p>

<p><img src="/img/ost_diagram.jpg" alt="diagram" /></p>

<p>This is a diagram of what happens when one data structure has 30 items and the other has 60 items. It contains all of the different cases for $latex k$. For example, when $latex k$ is 35, then we can discard the upper and lower thirds of the 30 item data structure, and we can discard the upper third of the 60 item data structure.</p>

<p>You can draw similar diagrams for the other cases.</p>

<p>This part is the sketchiest part of the whole algorithm. I’m pretty sure that you can always decrease at least one of the data structures by one third. I’m not sure if you can always shrink both of them. I’m not sure how much you can shrink the OST in constant time; I’m pretty sure you can do at least $latex \frac 16$, and I think that for any fraction less than $latex \frac 13$, you can choose a node depth such that you can always cut that fraction out in constant time.</p>

<h3 id="runtime-of-this-solution">Runtime of this solution</h3>

<p>If one of the data structures starts out much larger than the other one, it will shrink until they’re similar sizes. This takes $latex O(m)$ time for the array and $latex O(\log(n))$ time for the OST.</p>

<p>Once they’re the same size, I think that at least one of them will both shrink by one third every time. So we have the recurrence relation:</p>

<script type="math/tex; mode=display">f(n, m) = f \left( \frac {2n}3, \frac {2m}3\right) + m + 1</script>

<p>which evaluates to $latex \log(n) + m$.</p>

<h2 id="conclusion">Conclusion</h2>

<p>So we can do quick select on an OST and array at the same time in $latex O(m + \log(n))$.</p>

<p>My work here leaves a lot to be desired. Most obviously, my fastest algorithm is extremely complicated and inelegant; I bet that can be simplified.</p>

  </div>

  <hr />

  <h2><a href="/2016/06/02/say.html"> Not thinking of things I can't say</a></h2>

  <p class="post-meta"><time datetime="2016-06-02T00:00:00-07:00" itemprop="datePublished">Jun 2, 2016</time></p>

  <div class="shrink-headings">
    <p>I noticed recently that I usually don’t think of thoughts which I’m not going to be able to say for political correctness reasons. Occasionally when I talk to people who don’t care about offending progressives, they say really insightful things which I would never have thought of on my own, because my brain just blocks those thoughts out before I can think them.</p>

<p>This is annoying, because I’d rather think of things like that and not say them publicly than not think of them at all.</p>

<p>I think the main cause of this is that I do a lot of my thinking while talking to people about things, and if certain kinds of discussion are stifled, I don’t get practice thinking about them.</p>

<p>This has a few implications. Firstly, it means that efforts to stifle offensive thoughts concern me somewhat more than they did previously, because I am more concerned that restricting speech restricts thoughts. Secondly, it makes me think more that private spaces for conversations are important. Third, it makes me really glad for circle-jerking EAs who are privately enjoy biting bullets and saying purposefully controversial things—I’d previously thought of that as harmless fun, but now I think that it might have the important function of countering the natural push towards orthodoxy.</p>

<hr />

<p><a href="https://www.facebook.com/bshlgrs/posts/10207784018613166">view comments on Facebook</a></p>

  </div>

  <hr />


<p><a href="/posts">All posts</a></p>

<p><a href="/feed.xml">RSS feed</a></p>

<script>
$(function() {
  $(".shrink-headings").map(function(idx, div) {
    $(div).html(
      $(div)
        .html()
        .replace(/<h4/g, "<h5")
        .replace(/<h3/g, "<h4")
        .replace(/<h2/g, "<h3")
    )
  })
})
</script>


      <hr/>

<div class="PageNavigation">
  
  
</div>

    </div>
    <div class="col-sm-3 col-sm-offset-1">
      <img src="https://scontent-sjc2-1.xx.fbcdn.net/hphotos-xtp1/t31.0-8/11154688_10205041372168719_3725604149367069581_o.jpg" class="img-responsive" alt="Picture of Buck">
      
<hr/>
<a class="arrow" href="/"><strong>Buck</strong></a>
<ul>
  <li><a class="arrow" href="/about">About</a>
    <ul>
      <li><a href="http://triplebyte.com?ref=bshlgrs.github.io">Triplebyte</a></li>
    </ul>
  </li>
  <li>Links
    <ul>
      <li>
          <a class="arrow" href="http://github.com/bshlgrs">GitHub</a>
      </li>
      <li>
          <a class="arrow" href="mailto:bshlegeris@gmail.com">Email</a>
      </li>
      <li>
          <a class="arrow" href="http://www.facebook.com/bshlgrs">Facebook</a>
      </li>
      <li>
          <a class="arrow" href="http://lnkd.in/bnBJ6EF">LinkedIn</a>
      </li>
      <li>
          <a class="arrow" href="/resume.pdf">Resume</a>
      </li>
    </ul>
  </li>
  <li><a class="arrow external" href="https://docs.google.com/forms/d/1SOombLPHlKIMut-wJzIRg7DGdJjh9PJV4yAkrmTXKn4/viewform?usp=send_form">Anonymous feedback</a></li>

  <li><a href="/posts" class="arrow">Blog</a>
    <ul>
      
        <li>
          <a class="arrow" href="/2016/07/02/hash-ordered-treaps.html">Hash-ordered treaps</a>
        </li>
      
        <li>
          <a class="arrow" href="/2016/06/30/triplebyte.html">You should work at Triplebyte</a>
        </li>
      
        <li>
          <a class="arrow" href="/2016/06/22/ctci.html">Studying for startup interviews with 'Cracking the Coding Interview'</a>
        </li>
      
        <li>
          <a class="arrow" href="/2016/06/16/kth-richest.html">'Who is the kth richest person with age between x and y'</a>
        </li>
      
        <li>
          <a class="arrow" href="/2016/06/16/generalized-multi-quickselect.html">Generalized multi-quickselect</a>
        </li>
      
        <li>
          <a class="arrow" href="/2016/06/15/multi-sorted-array-quickselect.html">Quickselect on multiple sorted arrays</a>
        </li>
      
        <li>
          <a class="arrow" href="/2016/06/12/quickselect-lemma.html">Quickselect on an unordered array and an order statistic tree</a>
        </li>
      
        <li>
          <a class="arrow" href="/2016/06/02/say.html">Not thinking of things I can't say</a>
        </li>
      
    </ul>
  </li>
  <li>
      <a class="arrow" href="/cute">Pictures of me</a>
  </li>
</ul>

    </div>
  </div>
</div>




    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Buck Shlegeris</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>Buck Shlegeris</li>
          <li><a href="mailto:bshlegeris@gmail.com">bshlegeris@gmail.com</a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/bshlgrs"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">bshlgrs</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/bshlgrs"><span class="icon icon--twitter"><svg viewBox="0 0 16 16"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">bshlgrs</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>Website of Buck Shlegeris.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-52980069-1', 'auto');
  ga('send', 'pageview');

</script>

</html>

