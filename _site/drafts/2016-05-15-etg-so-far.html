<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Earning to give, so far</title>
  <meta name="description" content="Website of Buck Shlegeris.
">


  <link rel="stylesheet" href="/css/main.css">
  <link rel="stylesheet" href="/bootstrap.css">
  <link rel="canonical" href="http://bshlgrs.github.io/drafts/2016-05-15-etg-so-far.html">
  <link rel="alternate" type="application/rss+xml" title="Buck Shlegeris" href="http://bshlgrs.github.io/feed.xml">
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$latex', '$'] ],
        displayMath: [ ['$$', '$$']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      messageStyle: "none",
      "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
    });
  </script>
  <script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
  <script src="/jquery.js"></script>
  <script type="text/babel" src="/main.js"></script>
  
</head>


  <body>

    

    <div class="container">
  <div class="row">
    <div class="col-xs-6 col-xs-offset-1">
      <h1 class="post-title" itemprop="name headline">Earning to give, so far</h1>
      <p class="post-meta"><time datetime="2016-07-14T00:00:00-07:00" itemprop="datePublished">Jul 14, 2016</time></p>

      <hr/>

      <p>I’ve been earning to give since early 2014. I think I’ve made some good decisions and some serious mistakes so far. Here’s a history of what I was thinking, what I did, and how sensible I think my decisions were with the benefit of hindsight.</p>

<h2 id="history-of-my-donations">History of my donations</h2>

<h3 id="section">2014</h3>

<p>The donation opportunity landscape was very different in 2014. Good Ventures was already putting a lot of money into global poverty, but Holden seemed to not care about animals, and he seemed excessively skeptical of x-risk reduction. EA was growing rapidly, and it seemed inevitable that a lot more money was going to get involved, but it wasn’t at all clear to me whether much of that money would be targeted towards x-risk or animals. (I knew that GiveWell was interested in things outside global poverty (GiveWell Labs had been around since 2011), but it wasn’t clear that they wanted this to be their main focus long term.)</p>

<p>I identified pretty actively as an animal-focused EA back then: I <a href="http://bshlgrs.tumblr.com/post/90910214488/ambition">wrote</a> “I currently want to oppose speciesism, but could be convinced to work on existential risk instead.”</p>

<p>I donated my $5000 to Animal Charity Evaluators in 2014 basically because I thought EA was going to grow a bunch, and I wanted to make concern about animals relatively more prominent in the movement, reasoning that it would be cheaper to do this before EA was more popular. At the time, I didn’t really think about whether I should consider donating to far future organizations instead. (I also donated $500 to Vegan Outreach, $500 to 80,000 Hours, and $60 to MIRI.) This was about 10% of my income–I didn’t earn that much because I only worked for about half the year.</p>

<h3 id="section-1">2015</h3>

<p>I started working full time as a software engineer in 2015. In the first half of 2015, a lot more funding appeared for animals and x-risk reduction. In January, FLI announced Elon Musk’s $10m donation to AI safety research. In June, GiveWell announced that they were starting a factory farming project which would be donating $5m a year. GiveWell’s interest in x-risk also became clearer to me.</p>

<p>This changed my calculations a lot. I became less interested in funding animal stuff. I trust the Open Philanthropy Project’s judgement a lot, and Good Ventures has a lot of money. I also thought that when the Open Philanthropy project started making animal welfare donation recommendations, it was plausible that some of the “we don’t know enough about animal interventions to fund them” crowd would shift their donations away from global poverty to animals. (This doesn’t really seem to have happened much yet; plausibly animal EAs aren’t working hard enough to cannibalize this funding.)</p>

<p>I also started to feel like there was less room for my donations in the far future space. I thought that I possibly still had a comparative advantage over OpenPhil at funding good AI safety research, because I thought OpenPhil and FLI might end up funding things I thought were less valuable–maybe they’d fund work on technological unemployment or similar things, or maybe they’d be irrationally biased against weird-sounding organizations like MIRI. However, my opinion of OpenPhil increased through the later half of 2015. This was largely because Claire Zabel started working there and spoke highly of it. I trust her judgement and we have similar values, so this was very persuasive to me. The other major factor is that OpenPhil hired several people whose opinions on x-risk I trusted, including Nick Beckstead, Luke Muehlhauser, and Daniel Dewey. Also, I got to know Howie Lempel a little more and he gave me more confidence that OpenPhil cared about the future and animals properly.</p>

<p>Michael Dickens thought a bunch about cause prioritization in mid 2015, and wrote a long post about his donation decisions which ended up favoring <a href="http://effective-altruism.com/ea/ns/my_cause_selection_michael_dickens/">Raising for Effective Giving</a>. I think his reasoning at the time was quite good.</p>

<p>I waited until the end of the year and I still wasn’t sure where I should donate. So I put my money in a donor-advised fund to grow until I had better information. (I also donated to $2500 to MIRI in September to take advantage of my PayPal donation matching.) I haven’t yet donated it anywhere.</p>

<hr />

<h2 id="hindsight">Hindsight</h2>

<h3 id="excessive-optimism-about-specific-animal-causes">Excessive optimism about specific animal causes</h3>

<p>I was bullish on specific animal rights interventions like leafletting and online ads that don’t have very strong evidence of effectiveness. I should have been more skeptical about those. I’m not sure that those interventions are ineffective–Eitan Fisher still thinks they’re good–but I’m much less confident than I was in 2014.</p>

<p>I made this mistake because of emotional bias. I was frustrated by people who advocated for global poverty charities for dumb reasons. A lot of them hadn’t thought much about animal suffering, which I thought was embarrasingly negligent. And a lot of them claimed to prefer human-targeting charities because of the stronger evidence base; I thought that if they really had that belief, they should either save their money just in case we found a great intervention for animals in the future, or donate it to the people who were trying to find effective animal right interventions.</p>

<p>There is an argument I could have used back then that I agree with, but I didn’t actually use it explicitly. It wasn’t obvious that any particular intervention to reduce animal suffering was more cost effective, but I would have given more than 50% credence that in a few years we’d know about an intervention for animal suffering which was 10x more cost effective than the best global poverty intervention. (I was right: by OpenPhil’s numbers, corporate campaigns for welfare reforms are probably about 10,000x more cost effective than AMF.) Given that belief, saving money for a few years while we waited for more information on factory farming interventions seemed to be obviously better than giving to AMF immediately.</p>

<p>I donated about $500 to Vegan Outreach in 2014, which isn’t much money, but it was still probably a mistake.</p>

<p><strong>Lesson learned: don’t have a belief just because most of the arguments against it are bad or dishonest.</strong> This is obvious, but apparently I didn’t do it right.</p>

<h3 id="not-thinking-enough-about-rfmf-concerns-early">Not thinking enough about RFMF concerns early</h3>

<p>I am no longer sure earning to give makes sense, basically because OpenPhil seems pretty committed to funding all of the things which I think are valuable. I guess I’ve always known this could happen. But I don’t think I took it seriously enough until recently.</p>

<p>In hindsight I wish that I tried harder to get a clear picture of OpenPhil’s values and plans back in 2014. I could have engaged more with them on their blog; I could have more purposefully sought out OpenPhil employees and talked to them.</p>

<p>On the plus side, I chose to finish my degree instead of working immediately, which was a tradeoff which looks better now that I’m not sure I’ll be earning to give long term. I’m glad I thought to do that at the time.</p>

<p><strong>Lesson learned: when your decisions depend crucially on something which you don’t know much about, there is very high information value in investigating that thing.</strong></p>

<h3 id="not-thinking-enough-about-miri">Not thinking enough about MIRI</h3>

<p>I thought MIRI was plausibly a good donation target, but I didn’t think properly about it until mid 2015. This prevented me from giving to them back when they were more funding constrained than they are now.</p>

<p>The lesson learned here was basically the same as the previous one.</p>

<h2 id="conclusion">Conclusion</h2>



    </div>
    <div class="col-xs-3 col-xs-offset-1">
      <img src="https://scontent-sjc2-1.xx.fbcdn.net/hphotos-xtp1/t31.0-8/11154688_10205041372168719_3725604149367069581_o.jpg" class="img-responsive" alt="Picture of Buck">
      <hr/>
      <a href="/">Buck Shlegeris</a>
      <hr/>
      <p>Other posts</p>
      <ul>
        
          <li>
            <a class="arrow" href="/2016/05/29/explicit.html">Optimize dating for non-interference with platonic relationships</a>
          </li>
        
          <li>
            <a class="arrow" href="/2016/05/29/flinching.html">Flinching away from hard things</a>
          </li>
        
          <li>
            <a class="arrow" href="/2016/05/24/mistakes.html">My main effective altruism mistakes so far</a>
          </li>
        
          <li>
            <a class="arrow" href="/2016/04/22/dumbest-algorithm-problem.html">The dumbest algorithm problem in the entire world</a>
          </li>
        
          <li>
            <a class="arrow" href="/2016/04/20/overteaching.html">Overteaching and overlearning</a>
          </li>
        
          <li>
            <a class="arrow" href="/2016/04/14/hyperactive-record.html">Hyperactive Record</a>
          </li>
        
          <li>
            <a class="arrow" href="/2016/04/03/data-structure-projects.html">Data structure projects</a>
          </li>
        
          <li>
            <a class="arrow" href="/2016/02/21/dxe.html">DxE at Stanford</a>
          </li>
        
          <li>
            <a class="arrow" href="/2016/02/21/learning-fun.html">Optimize for fun when you're trying to learn</a>
          </li>
        
          <li>
            <a class="arrow" href="/2016/02/19/bleg-for-intro-to-web-architecture.html">Bleg for intro to web architecture</a>
          </li>
        
          <li>
            <a class="arrow" href="/2016/02/01/tech_conferences.html">For Programmers, Giving a Talk at a Conference May Be Worth $100/hr in Career Capital</a>
          </li>
        
          <li>
            <a class="arrow" href="/2016/01/17/piano.html">Tips for learning to play rock piano</a>
          </li>
        
          <li>
            <a class="arrow" href="/2015/08/08/poly-np.html">Poly NP</a>
          </li>
        
          <li>
            <a class="arrow" href="/2015/08/08/haskell_set.html">Sets as functions</a>
          </li>
        
          <li>
            <a class="arrow" href="/2015/08/08/value-of-life.html">Saving lives vs improving them</a>
          </li>
        
      </ul>
    </div>
  </div>
</div>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-52980069-1', 'auto');
  ga('send', 'pageview');

</script>


    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Buck Shlegeris</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>Buck Shlegeris</li>
          <li><a href="mailto:bshlegeris@gmail.com">bshlegeris@gmail.com</a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/bshlgrs"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">bshlgrs</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/bshlgrs"><span class="icon icon--twitter"><svg viewBox="0 0 16 16"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">bshlgrs</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>Website of Buck Shlegeris.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
