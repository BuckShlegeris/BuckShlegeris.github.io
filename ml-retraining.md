---
layout: post
title:  "ML retraining grants"
date:   2020-01-01
---

Here are some notes on the ML retraining grants that MIRI runs, funded by [Open Phil](https://www.openphilanthropy.org/focus/global-catastrophic-risks/potential-risks-advanced-artificial-intelligence/machine-intelligence-research-institute-ai-safety-retraining-program).

## What is the goal?

This grant program tries to be a lightweight vehicle for to give people time and a little bit of support to try to study ML and turn into people who can do useful ML-based safety research.

Also giving people time off so that it's easier for them to do things like spend a while hanging around in the SF Bay Area talking to people who are interested in AI safety, or coming to [AIRCS workshop](https://intelligence.org/ai-risk-for-computer-scientists/).

## What do people do?

Typically, people do something like:

- replicate a bunch of deep RL papers, following [Spinning Up in Deep RL](https://spinningup.openai.com/) or something similar.
- learn fundamentals of ML, eg with Bishop's 'Pattern Recognition and Machine Learning' and with Goodfellow et al's 'Deep Learning'
- try to make variations on the papers they've replicated
- learn more generally about areas of ML that interest them.
- towards the end of the three months, apply for jobs in AI safety

Typically, people focus on deep RL rather than other areas of ML, because:

- it's plausibly the area of ML most related to what the first transformative AI systems will be like
- you can replicate a lot of interesting work without having to spend as much on compute power.
- more AI safety research relies on deep RL than other kinds of ML.

## What types of people receive grants?

People who have substantial experience in software engineering or other quantitative fields, and who I believe are going to be able to learn the math involved in deep reinforcement learning. For example, I think it's important that you be able to understand the contents of [this page](https://spinningup.openai.com/en/latest/spinningup/rl_intro3.html) as part of learning deep RL. (That page is the third page in a series, so it's fine if you don't immediately know what it's talking about, but if you have never read and understood pages that look that mathy, I am less enthusiastic about funding you.) This requires being comfortable with calculus on vectors and matrices, and some probability theory.

Because this grant involves fairly self-directed study, I usually give the grant to people who I have met for some other reason, because I've already taken the time to get to know them. I recently experimented with advertising the program on the 80000 Hours job board. I am probably going to have a pretty high bar for applications from people who I don't already have much of a sense of.

## What happens after the grant?

I've given three of these grants. One person got a job doing AI safety work. Another applied to some AI safety jobs, didn't get those jobs, and then got a normal software engineering job and plans to try to move into AI safety again at some point in the future. A third got another three months of funding from me to spend more time studying ML and pursuing his own AI safety research directions.

This grant doesn't come with a guaranteed MIRI job at the end of it, though we often offer the grant to people who we think might be good MIRI fits.

## How do I apply?

Email me (Buck) with a resume, he'll send you some more questions to answer. Due to time constraints, I have a pretty high bar with these grants.
